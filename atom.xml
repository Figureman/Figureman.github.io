<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>故乡渊</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2023-05-05T17:42:07.002Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>Jww</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Anchor-based and Anchor-free 概念理解2</title>
    <link href="http://example.com/2023/05/02/CV%E6%A6%82%E5%BF%B5%E7%90%86%E8%A7%A3%20-%20%E5%89%AF%E6%9C%AC/"/>
    <id>http://example.com/2023/05/02/CV%E6%A6%82%E5%BF%B5%E7%90%86%E8%A7%A3%20-%20%E5%89%AF%E6%9C%AC/</id>
    <published>2023-05-01T16:00:00.000Z</published>
    <updated>2023-05-05T17:42:07.002Z</updated>
    
    <content type="html"><![CDATA[<h2>十七、RetinaNet简要介绍</h2><p>RetinaNet是一种用于目标检测的深度学习模型，由Facebook AI Research提出。它是一种基于单级检测器（one-stage detector）的检测器，可以同时预测多个尺度和不同宽高比的目标框，并且在目标检测的准确性和速度方面都具有很好的表现。</p><p>RetinaNet的核心思想是引入了一种名为Focal Loss的新的损失函数。这个损失函数可以有效地解决单级检测器在处理大量背景样本和少量正样本时的类别不平衡问题，从而提高目标检测的准确性。</p><p>RetinaNet的架构由两个主要组成部分构成：特征提取网络和预测网络。特征提取网络通常是一个预训练的卷积神经网络（如ResNet、Inception等），用于提取图像特征。预测网络包括一个特征金字塔网络（Feature Pyramid Network，FPN）和一个预测头（prediction head），用于生成目标框的位置和类别预测。</p><p>在RetinaNet中，特征金字塔网络可以生成一系列具有不同尺度和语义级别的特征图。预测头则包括两个子网络：一个用于生成目标框的位置偏移量（即边界框回归器），另一个用于预测每个目标框的类别（即分类器）。这两个子网络在不同尺度的特征图上进行操作，以便同时检测不同大小和宽高比的目标。</p><p>总体来说，RetinaNet是一种简单而有效的目标检测器，通过引入新的损失函数和设计特征金字塔网络来提高单级检测器的准确性，并在多个目标检测基准测试中取得了很好的成绩。</p><p>RetinaNet的整体流程可以分为以下几个步骤：</p><ol><li>特征提取：输入图像经过卷积神经网络（如ResNet等）进行特征提取，得到一系列具有不同尺度和语义级别的特征图。</li><li>特征金字塔网络：特征金字塔网络（Feature Pyramid Network，FPN）将不同尺度的特征图进行融合，生成一系列具有不同分辨率的特征金字塔。</li><li>预测头：对于每个特征金字塔，预测头包括两个子网络：一个用于生成目标框的位置偏移量（即边界框回归器），另一个用于预测每个目标框的类别（即分类器）。</li><li>Anchor生成：对于每个特征金字塔，根据其分辨率和比例，生成一组anchor boxes，用于对检测目标进行采样。</li><li>目标检测：对于每个特征金字塔和对应的anchor boxes，使用边界框回归器和分类器进行目标检测。具体地，分类器输出每个anchor box中各个类别的概率，而边界框回归器则预测每个anchor box与实际目标框之间的偏移量，从而生成最终的目标框。</li><li>Focal Loss：使用Focal Loss作为损失函数，对分类器的输出进行优化，以解决单级检测器中类别不平衡的问题，从而提高目标检测的准确性。</li><li>NMS：使用非极大值抑制（NMS）进行目标框的筛选，去除重叠度较高的目标框，得到最终的目标检测结果。</li></ol><p>总体来说，RetinaNet通过特征金字塔网络和Focal Loss等方法，克服了单级检测器在处理大量背景样本和少量正样本时的类别不平衡问题，从而在目标检测的准确性和速度方面都具有很好的表现。</p><h2>十八、FCOS流程</h2><p>FCOS（Fully Convolutional One-Stage Object Detection）是一种基于全卷积网络的单阶段目标检测方法，其流程如下：</p><ol><li>特征提取：输入图像通过卷积神经网络（如ResNet等）进行特征提取，得到一系列特征图。</li><li>特征金字塔网络：对于每个特征图，使用特征金字塔网络（Feature Pyramid Network，FPN）进行跨尺度特征融合，生成一组具有不同分辨率的特征金字塔。</li><li>分类头和回归头：在每个特征金字塔上，使用分类头和回归头分别预测每个像素点是否为物体以及物体的位置和大小。</li><li>Anchor-free检测：与RetinaNet不同，FCOS是一种anchor-free检测方法，它不需要预定义的anchor boxes。相反，对于每个像素点，使用回归头预测它相对于物体的中心点和大小，从而生成目标框。</li><li>损失函数：FCOS使用IoU Loss作为损失函数，以衡量预测框与真实框之间的重叠程度。同时，FCOS还使用了Center-ness Loss来约束目标框的中心点，以进一步提高检测精度。</li><li>NMS：使用非极大值抑制（NMS）进行目标框的筛选，去除重叠度较高的目标框，得到最终的目标检测结果。</li></ol><p>总体来说，FCOS通过使用全卷积网络和IoU Loss等方法，实现了无需anchor boxes的目标检测，从而在保证准确性的同时大大降低了计算复杂度，具有较高的实用价值。</p><h2>十九、FCOS和Retainnet 如何定义正负样本</h2><p>在RetinaNet中，模型首先计算每个anchor box与ground-truth box之间的IoU（交并比），如果IoU大于预设的阈值θp，则将该anchor box标记为正样本；如果IoU小于预设的阈值θn，则将该anchor box标记为负样本；对于IoU在阈值范围内的anchor box，则被忽略不参与训练。这种方式适用于anchor-based的检测模型，因为它们将anchor box作为预设样本。</p><p>而在FCOS中，模型采用了基于空间和尺度约束的方法来定义正负样本。具体来说，对于每个ground-truth box，模型会在其周围的一定范围内选取一组anchor points，并将它们标记为候选正样本。然后，根据预设的尺度范围，从这些候选正样本中选取最佳的正样本，并将剩下的anchor points标记为负样本。这种方式适用于anchor-free的检测模型，因为它们将目标的中心点作为预设样本。</p><p>总之，两种模型的正负样本定义方式略有不同，但都基于IoU或空间尺度约束，并且都旨在使正样本和负样本具有代表性，提高模型的训练效果。</p><p>在FCOS中，预设的尺度范围是为每个特征金字塔层级定义的。具体来说，对于第k层的金字塔特征图，设其步长为sk，那么预设的尺度范围为 [sk/2, 2sk]。这个范围的含义是：对于第k层特征图上的每个anchor point，它们的有效感受野（effective receptive field）应该在以目标中心为中心、宽高为 [sk/2, 2sk] 的区域内。只有落在这个区域内的anchor point才会被视为正样本，否则就被标记为负样本。</p><p>在训练过程中，模型会根据目标的真实尺度（即目标的宽高）来动态地调整预设的尺度范围，从而使得正负样本的定义更加准确。具体来说，对于每个ground-truth box，模型会计算其真实宽高与预设尺度范围的比值，然后根据这个比值来调整预设的尺度范围。这样做的好处是，能够在不同尺度的特征金字塔层级上更加准确地定义正负样本，从而提高模型的检测效果。</p><h2>二十、请详细解释FCOS和Retainnet的Regression starting status</h2><p>在目标检测中，回归模块的任务是对预测框进行微调，从而更精确地匹配目标的位置。RetinaNet和FCOS在回归模块的实现上略有不同，其中Regression starting status是一个重要的概念。</p><p>RetinaNet中，回归模块的输入是一个anchor box和对应的分类概率，输出是该anchor box的边界框坐标偏移量。为了让回归模块更容易学习到边界框的位置信息，RetinaNet采用了一种称为“Regression starting status”的策略。具体来说，对于每个anchor box，RetinaNet在训练开始时先计算它与所有ground truth boxes的IoU值，并选取IoU最高的那个ground truth box作为该anchor box的起始位置，然后再对其进行微调。这个起始位置相当于是回归模块的初始输入，有助于加速模型的收敛。</p><p>FCOS中，回归模块的输入是一个像素点的坐标以及对应的分类概率，输出是该点到目标边界框四个边界的距离。为了更好地学习到边界框的位置信息，FCOS同样采用了Regression starting status策略。具体来说，FCOS在训练开始时会预先计算每个ground truth box的中心点与特征图上所有像素点的距离，并将这些距离转换为初始回归值。这样，在后续的训练过程中，回归模块只需要微调这些初始值即可，大大加快了模型的收敛速度。需要注意的是，FCOS在计算初始回归值时还会根据ground truth box的大小调整其对应的特征金字塔层级，从而进一步提高模型的精度。</p><h2>二十一、GroupNorm  GIoU Loss In GT Box Centerness  Scalar 简要解释这五个改善措施</h2><p>这五个改善措施是针对目标检测中存在的问题进行的改进，简要解释如下：</p><ol><li>GroupNorm：在传统的批标准化（Batch Normalization，BN）中，小批量样本会导致较大的方差和偏移，使得模型难以收敛。而Group Normalization（GN）则是将通道分为若干组，每组计算均值和方差，从而减小了mini-batch size的依赖，稳定了归一化效果。</li><li>GIoU Loss：传统的目标检测损失函数，如IoU Loss、Smooth L1 Loss等，不能完全衡量预测框与真实框之间的重叠度。而 Generalized IoU Loss（GIoU Loss）考虑了预测框与真实框之间的完全重叠情况，从而更准确地衡量二者之间的重叠度。</li><li>In GT Box：在预测框回归中，传统方法会将所有样本视为负样本，仅仅关注预测框和真实框之间的差异。而在 GT Box 中，只有位于真实边界框内部的样本被视为正样本，使得模型更专注于内部样本的学习。</li><li>Centerness Scalar：在 RetinaNet 中，引入了一个额外的centerness值，用于衡量预测框与目标中心点的距离，从而更加关注包围目标的预测框是否包含目标中心，而不是仅仅关注重叠度。</li><li>Adaptive Training Sample Selection：在 FCOS 中，引入了自适应训练样本选择机制，将样本的权重与预测框中心到真实框边界的距离相关联，更加关注离真实框较近的预测框，有效地减少了负样本对模型的干扰。</li></ol><h2>二十二、AP性能</h2><p>平均精度（Average Precision，AP）是衡量目标检测算法性能的一种常用指标。它基于精确率-召回率曲线（Precision-Recall Curve，PR曲线）计算得到。在目标检测任务中，精确率表示检测出的物体中真正属于目标物体的比例，而召回率表示所有真正属于目标物体的物体中被正确检测到的比例。PR曲线展示了精确率和召回率之间的关系。</p><p>平均精度的计算方法是对PR曲线下的面积进行积分得到，具体来说，对PR曲线进行离散化，计算每个点的精确率和召回率，然后对这些点进行插值，计算出PR曲线下的面积，最后取平均值作为平均精度。</p><p>AP的取值范围在0到1之间，值越大表示检测算法的性能越好。一般来说，AP值大于0.5就可以认为是一个比较好的检测算法，AP值大于0.8可以认为是一个非常好的检测算法。</p><h2>二十三、ATSS为什么要使用均值和方差作为它的阈值</h2><p>ATSS算法使用均值和标准差的和作为IoU阈值的原因是为了动态地调整正负样本的阈值，从而更好地适应不同的数据集和目标。传统的目标检测算法使用固定的IoU阈值来划分正负样本，但是这种方法容易受到数据集中目标尺寸和密度的影响，导致检测性能下降。而ATSS算法使用均值和标准差的和来自适应地调整阈值，能够更好地适应不同的目标尺寸和密度，从而提高检测性能。具体来说，当目标比较稀疏时，使用较小的阈值可以更好地保留目标，而当目标比较密集时，使用较大的阈值可以减少误检。因此，使用均值和标准差的和作为IoU阈值可以使ATSS算法更加灵活和高效。</p><p>使用均值作为阈值的优点是，它可以反映出正负样本的平衡情况。对于一个较为平衡的数据集，正负样本的数量相对均衡，此时使用均值作为阈值可以更好地反映正负样本的覆盖情况。而如果使用一个固定的阈值，可能会导致正负样本的覆盖不均衡，从而影响模型的性能。因此，在正负样本的数量相对均衡时，使用均值作为阈值可以提高模型的鲁棒性和泛化性能。</p><p>使用方差作为阈值的优点是可以提高模型的鲁棒性。方差反映了样本数据分布的离散程度，如果数据分布比较分散，则方差较大，反之亦然。因此，使用方差可以考虑数据分布的变化范围，从而更加准确地确定阈值，避免了因单一阈值无法满足不同数据分布的情况而导致的模型泛化性能下降的问题。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2&gt;十七、RetinaNet简要介绍&lt;/h2&gt;

&lt;p&gt;RetinaNet是一种用于目标检测的深度学习模型，由Facebook AI Research提出。它是一种基于单级检测器（one-stage detector）的检测器，可以同时预测多个尺度和不同宽高比的目标框，并且在</summary>
      
    
    
    
    <category term="计算机视觉" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="目标检测" scheme="http://example.com/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"/>
    
    <category term="计算机视觉" scheme="http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
  </entry>
  
  <entry>
    <title>Anchor-based and Anchor-free 概念理解</title>
    <link href="http://example.com/2023/05/02/CV%E6%A6%82%E5%BF%B5%E7%90%86%E8%A7%A3/"/>
    <id>http://example.com/2023/05/02/CV%E6%A6%82%E5%BF%B5%E7%90%86%E8%A7%A3/</id>
    <published>2023-05-01T16:00:00.000Z</published>
    <updated>2023-05-05T17:35:13.022Z</updated>
    
    <content type="html"><![CDATA[<h2>一、FPN</h2>FPN是特征金字塔网络（Feature Pyramid Network）的缩写，是一种用于目标检测的深度学习模型。相较于传统的卷积神经网络（CNN），FPN的最大特点在于它可以生成不同尺度的特征金字塔，为检测不同大小物体提供支持。FPN模型在目标检测中的核心思想是提出一种新的特征提取方法，该方法可以产生具有不同尺度信息的特征金字塔，其中较低层级的金字塔主要用于检测较小的目标，而较高层级的金字塔主要用于检测较大的目标。FPN模型将金字塔中的特征图沿着空间维度上采样，并和低层级的特征图进行融合，从而产生具有不同尺度信息的特征金字塔。FPN模型不仅可以提高目标检测的准确率，而且可以提高模型的速度和效率。在目标检测任务中，FPN模型经常被用来检测不同大小的目标，并且在许多比赛和实际应用中表现优异，如COCO2017比赛、物体检测、图像分割等领域。<h2>二、Focal Loss</h2><p>Focal Loss是一种用于解决类别不平衡问题的损失函数，在2017年提出并广泛应用于目标检测和图像分割等领域。它是由Ross Girshick等人提出的一篇论文”Focal Loss for Dense Object Detection”中提出的。</p><p>在目标检测和图像分割等任务中，常常会遇到类别不平衡的情况，即某些类别的样本数量远多于其他类别的样本数量。这种情况下，传统的交叉熵损失函数会将大量的权重分配给数量较多的类别，导致少量的类别被忽视，从而影响模型的性能。</p><p>Focal Loss通过引入一个平衡因子，来缓解类别不平衡问题，该平衡因子主要通过减小易分类样本的权重来实现，同时增加难分类样本的权重。具体来说，Focal Loss对于易分类的样本，降低了它们的权重，从而减少了其对损失函数的贡献；对于难分类的样本，增加了它们的权重，从而增加了其对损失函数的贡献。这种方法可以使模型更加关注难分类样本，提高模型的性能。</p><p>在目标检测和图像分割等领域，Focal Loss已经被广泛应用于各种深度学习模型中，并取得了显著的性能提升。</p><h2>三、FPN模型和Focal Loss 对 anchor-free的影响</h2><p>PN模型和Focal Loss对anchor-free目标检测的影响如下：</p><ol><li>FPN模型：FPN模型可以生成不同尺度的特征金字塔，其中较低层级的金字塔主要用于检测较小的目标，而较高层级的金字塔主要用于检测较大的目标。对于anchor-free目标检测，FPN模型可以提供多尺度的特征金字塔，有利于检测不同大小的目标。因此，FPN模型在anchor-free目标检测中也被广泛应用。</li><li>Focal Loss：Focal Loss对于易分类的样本，降低了它们的权重，从而减少了其对损失函数的贡献；对于难分类的样本，增加了它们的权重，从而增加了其对损失函数的贡献。在anchor-free目标检测中，Focal Loss可以使模型更加关注难以分类的目标，提高模型的性能。</li></ol><p>综上所述，FPN模型和Focal Loss都可以对anchor-free目标检测产生积极的影响。在实际应用中，它们经常被同时应用于anchor-free目标检测中，以提高检测的准确率和效率。</p><h2>四、为什么有了FPN模型和Focal Loss ， anchor-free越来越受欢迎</h2><p>有了FPN模型和Focal Loss，anchor-free目标检测越来越受欢迎，主要有以下原因：</p><ol><li>更加灵活：相比于传统的anchor-based目标检测方法，anchor-free方法不需要提前定义一组锚点，因此更加灵活。这意味着anchor-free方法可以应用于各种不同的目标检测场景，例如目标大小和形状不确定的情况。</li><li>更高效：在anchor-based方法中，每个锚点都需要进行预测，因此会产生大量的冗余计算。而anchor-free方法则没有这个问题，因为它只需要对特征图中的像素进行分类和回归。这使得anchor-free方法在计算效率方面更有优势。</li><li>更加准确：FPN模型可以生成多尺度的特征金字塔，有利于检测不同大小的目标。Focal Loss可以使模型更加关注难以分类的目标，提高模型的性能。这些技术的应用使得anchor-free方法在准确率方面越来越接近传统的anchor-based方法，甚至超过了一些基于锚点的方法。</li></ol><p>综上所述，FPN模型和Focal Loss的出现，使得anchor-free方法在目标检测领域受到了越来越多的关注和应用。同时，随着深度学习技术的不断发展和优化，相信anchor-free方法将会在未来的目标检测领域中发挥越来越重要的作用。</p><h2>五、anchor-based目标检测方法可以分为one-stage和two-stage方法，请分别详细描述这两种方法，讨论他们的优点和缺点</h2><p>目标检测是计算机视觉领域的一个重要研究方向，其中anchor-based方法是常用的目标检测方法之一。它可以分为one-stage和two-stage方法，下面分别对这两种方法进行详细描述，并讨论它们的优缺点。</p><p><h3>1、One-stage方法</h3><br>One-stage方法是指在单个网络中完成目标检测的方法，最典型的代表是YOLO（You Only Look Once）和SSD（Single Shot MultiBox Detector）等。</p><p><h3>YOLO</h3><br>YOLO使用一个单独的卷积神经网络，直接对整张图片进行目标检测，具体流程如下：</p><ol><li>将输入图像划分为SxS个网格，每个网格负责预测B个边界框和C个类别概率。</li><li>对于每个边界框，预测其包含目标的置信度，以及其相对于该网格的坐标和大小。</li><li>最后根据置信度和类别概率筛选出目标并进行定位。</li></ol><p><h3>SSD</h3><br>SSD也是一种单阶段的目标检测方法，其主要思想是使用多尺度的卷积特征图进行检测。具体流程如下：</p><ol><li>对输入图像使用多尺度的卷积网络提取特征，得到多个不同大小的特征图。</li><li>对每个特征图，通过卷积层和预测层进行目标检测，得到每个位置的类别概率和边界框偏移量。</li><li>将所有特征图的预测结果合并，并通过非极大值抑制（NMS）筛选出目标。</li></ol><p><h4>One-stage方法的优点</h4></p><ol><li>实时性高：由于One-stage方法只需要对图像进行一次前向计算，因此它们的处理速度比Two-stage方法更快，适用于实时的目标检测场景。</li><li>目标检测精度高：One-stage方法可以通过增加网络深度、调整网络结构和损失函数等手段来提高检测精度，已经可以达到很高的性能。</li></ol><p><h4>One-stage方法的缺点</h4></p><ol><li>对小目标的检测不够准确：One-stage方法在检测小目标时，由于缺少多尺度特征金字塔和先验框等信息，容易出现误检或漏检的问题。</li><li>目标定位精度低：One-stage方法对于目标的定位精度不如Two-stage方法，因为它们缺乏ROI池化层或者其他明确的目标定位策略。</li></ol><p><h3>2、Two-stage方法</h3><br>Two-stage方法是指目标检测分为两个阶段进行，第一个阶段是在图像中提取一些候选区域，第二个阶段是对这些候选区域进行分类和定位，最典型的代表是Faster R-CNN和Mask R-CNN等。</p><p><h4>Faster R-CNN</h4><br>Faster R-CNN主要包含两个模块：Region Proposal Network（RPN）和Fast R-CNN。</p><ol><li>RPN：对输入图像进行卷积特征提取，并在每个特征点处产生多个不同尺寸和长宽比的锚点框（anchor box）。</li><li>Fast R-CNN：将RPN提取的锚点框作为候选区域，通过ROI pooling层将每个候选区域映射到固定大小的特征图上，再通过全连接层进行分类和回归。</li><li>最后通过非极大值抑制筛选出最终的目标框。</li></ol><p><h4>Mask R-CNN</h4><br>Mask R-CNN是在Faster R-CNN的基础上增加了一个Mask预测分支，可以同时进行目标检测和语义分割。</p><ol><li>RPN：同Faster R-CNN。</li><li>RoIAlign：对候选区域进行更精确的特征映射，得到每个候选区域的固定大小特征图。</li><li>分类和回归：同Faster R-CNN。</li><li>Mask分支：在每个RoI区域上进行预测，生成每个像素的目标掩码。</li></ol><p><h4>Two-stage方法的优点</h4></p><ol><li>对小目标检测更准确：Two-stage方法通过金字塔特征提取、RPN等策略可以生成不同尺度的候选区域，能够更准确地检测小目标。</li><li>目标定位精度更高：Two-stage方法在RoI pooling层等环节对目标进行定位，可以精确地定位目标的位置。</li></ol><p><h4>Two-stage方法的缺点</h4></p><ol><li>实时性较低：Two-stage方法需要对图像进行两次前向计算，速度较慢，适用于对实时性要求不高的场景。</li><li>设计和调参难度较大：Two-stage方法需要进行目标检测和提取候选区域两个任务的优化，需要在设计和调参上付出更多的努力。</li></ol><p>总的来说，One-stage方法适用于实时性要求高，目标检测精度要求适中的场景，Two-stage方法适用于对目标检测精度要求高，实时性要求适中的场景。</p><h2>六、Anchor-free detectors directly find objects without preset anchors in two different ways.</h2><p>Anchor-free目标检测器直接在图像中寻找物体而不需要预设锚点，可以分为两种不同的方式：</p><ol><li>CenterNet</li></ol><p>CenterNet直接在图像中寻找物体中心点，并以此为基础进行目标检测。具体来说，CenterNet使用高斯热力图来表示目标中心点，然后通过回归网络来输出目标框的位置和尺寸，并进行目标分类。在预测过程中，CenterNet将每个像素点都视为候选中心点，通过筛选出具有高响应值的中心点来实现目标检测。</p><ol><li>FCOS</li></ol><p>FCOS（Fully Convolutional One-Stage）是一种全卷积的、基于中心点的单阶段目标检测器。FCOS通过预测每个像素点对于物体中心点的距离和偏移量，来确定目标的位置和尺寸。同时，FCOS还引入了一个特征金字塔网络来处理不同尺度的特征图，并通过分类和回归来预测目标类别和边界框。与CenterNet不同，FCOS使用密集采样来获得足够多的正负样本，并且在训练过程中使用了一种新的损失函数来平衡不同大小的目标之间的重要性。</p><p>总的来说，CenterNet和FCOS都是基于中心点的Anchor-free目标检测器，它们不需要预设的锚点，具有更好的可解释性和泛化能力，但由于需要对每个像素点进行处理，因而在速度上可能有所欠缺。</p><h2>七、We use the ImageNet pretrained ResNet-50 with 5-level feature pyramid structure as the backbone.这句话中ResNet-50是用来干嘛的呢</h2>这句话中提到的ResNet-50是作为目标检测模型的骨干网络(backbone)来使用的。骨干网络负责从输入图像中提取特征，为后续的目标检测任务提供丰富的、具有多尺度特征的表示。在这篇论文中，作者使用了ImageNet预训练的ResNet-50作为骨干网络，通过5-level feature pyramid structure生成5个不同尺度的特征图，用于目标检测任务的实现。预训练的ResNet-50具有很强的图像特征提取能力，可以有效地提高目标检测的准确率和召回率。<h2>八、During training,we resize the input images to keep their shorter side being 800 and their longer side less or equal to 1, 333. 这句话是什么意思</h2>这句话的意思是，在训练过程中，作者将输入的图像调整大小，使它们的短边为800个像素，并且长边不超过1333个像素。这是因为在目标检测任务中，输入图像的大小对模型的精度和速度都有一定的影响。为了兼顾模型的精度和速度，通常需要对输入图像进行预处理，使它们的大小符合一定的规范。在这里，作者规定了一个较小的短边800像素，可以有效地控制模型的计算量，并且保证了模型能够检测到较小的目标。同时，由于较大的输入图像可能会降低模型的速度和精度，因此作者限制了长边的大小不超过1333个像素，以避免输入图像过大。<h2>九、After that, we use the preset score 0.05 to filter out plenty of background bounding boxes, and then output the top 1000 detections per feature pyramid这一步有什么作用。 preset score 0.05是什么意思</h2>这句话中的 "preset score 0.05" 指的是预设的置信度阈值，即筛选出置信度大于0.05的边界框。在目标检测中，置信度分数是指模型对于每个边界框所估计的该边界框包含目标的概率值，一般为0到1之间的实数。在这个阶段，筛选出置信度高于0.05的边界框可以去除很多背景框和错误的边界框，以保留置信度高、更有可能是真实目标的边界框。同时输出每个特征金字塔层级的前1000个检测结果，可以得到更多的目标检测结果，以提高模型的召回率，即检测到更多的真实目标。在目标检测任务中，置信度分数的计算方式通常由网络架构和损失函数共同决定。通常情况下，模型会为每个边界框输出一个包含两个值的向量，即分类得分和回归坐标值。分类得分表示该边界框属于目标类别的概率值，回归坐标值表示该边界框相对于anchor的坐标偏移值。在RetinaNet中，每个anchor对应的回归坐标值有4个，分别对应着边界框的左上角和右下角两个点的x,y坐标。模型会利用这些分类得分和回归坐标值来计算每个边界框的置信度分数，一般使用以下公式：score = cls_score * max(0, 1 - L1_distance(gt_box, pred_box) / w * h)其中，cls_score表示该边界框属于目标类别的分类得分，gt_box和pred_box分别表示真实边界框和预测边界框，L1_distance表示两个边界框之间的L1距离，w和h表示anchor的宽和高。这个公式的含义是，置信度分数由分类得分和预测框与真实框之间的重合程度共同决定，重合程度越高，置信度分数越大。最终，每个边界框的置信度分数会与预设的置信度阈值进行比较，保留分数大于阈值的边界框。<h2>十一、the Non-Maximum Suppres-sion (NMS)</h2>在目标检测中，同一个物体可能被不同的锚框（anchor box）所检测到，这时需要通过非极大值抑制（Non-Maximum Suppression，NMS）来去除重叠的框，保留置信度最高的那个框。具体来说，NMS的流程是这样的：1. 对所有的检测框按照置信度从高到低进行排序；2. 取出置信度最高的检测框，并将其加入最终的检测结果列表中；3. 对剩余的检测框进行以下操作：- 计算当前检测框与最终检测结果列表中已有框的重叠程度（一般使用IoU，即交并比）；- 如果重叠程度大于预设阈值，将此检测框舍去；- 如果重叠程度小于等于预设阈值，将此检测框加入最终检测结果列表中。1. 重复步骤2和3，直到所有检测框都被处理完毕。最终得到的结果是保留了置信度最高的框并且去除了与其重叠度较高的框的结果列表。<h2>十二、AP performance</h2>在目标检测中，AP是Average Precision的缩写，是一个用来衡量检测器检测精度的指标。它的计算方法是在不同的置信度阈值下，计算每个类别的precision和recall，并通过不同阈值下的面积累加得到平均准确率。AP值越高，说明检测器的性能越好。在目标检测中，AP是衡量检测算法性能的一个常用指标。对于每一个类别，AP值是通过计算precision-recall曲线下面积得到的，表示模型对该类别的检测能力。precision表示预测为该类别的bounding box中，有多少是正确的，而recall表示该类别的所有目标物体中，有多少被检测出来了。为了计算precision-recall曲线，我们需要首先对预测的bounding box按照置信度从高到低排序，然后在不同置信度阈值下计算precision和recall，然后将precision和recall的值绘制成曲线。AP值就是precision-recall曲线下面积的大小，值域从0到1。因为在不同的置信度阈值下，precision和recall的值会有所变化，所以AP值是一个综合了不同置信度下的检测性能的指标。<h2>十三、Furthermore, some new improvements have been made for FCOS including moving centerness to regression branch, using GIoU loss function and normalizing regression targets by corresponding strides.</h2>- Moving centerness to regression branch：在传统的FCOS中，中心度（用于度量目标距离特征图中心的距离）是与分类分支并行的单独分支。在这个改进中，中心度被移动到了回归分支，与边界框的偏移和宽高一起进行预测，从而可以共享更多的特征信息。- Using GIoU loss function：传统的IoU损失函数通常用于度量预测边界框和实际边界框之间的重叠程度。然而，IoU损失没有考虑边界框之间的间隙，而GIoU损失将这些间隙考虑在内，可以更好地反映边界框的拟合情况。- Normalizing regression targets by corresponding strides.：传统的FCOS中，回归目标是以像素为单位计算的。这个改进将回归目标标准化为特征图上对应的步长，使得不同尺度的目标具有相同的回归范围。<h2>十四、However, part of the AP gap between the anchor-based detector (32.5%) and the anchor-free detector (37.8%) results from some universal improvements that are proposed or used in FCOS, such as adding GroupNorm in heads, using the GIoU  regression loss function, limiting positive samples in the ground-truth box [56], introducing the centerness branch [56] and adding a trainablescalar [56] for each level feature pyramid.</h2><p>这句话是在讨论 anchor-based 检测器和 anchor-free 检测器之间性能差距的原因。作者指出，这两种检测器的性能差距不完全是由于 anchor-free 检测器的优越性导致的，而是由于在 anchor-free 检测器中使用了一些新的改进方法，这些方法也可以应用于 anchor-based 检测器中。</p><p>这些改进方法对于 anchor-based 和 anchor-free 检测器都有帮助，并且有助于缩小两者之间的性能差距。</p><ol><li>添加 GroupNorm [62]：传统的 BatchNorm 是在 batch 维度上进行标准化的，而 GroupNorm 是在 channel 维度上进行标准化的。在目标检测任务中，batch size 很小，因此使用 GroupNorm 可以更好地适应小批量数据。</li><li>使用 GIoU [48] 回归损失函数：GIoU 是一种与 IOU 相关的评估指标，它可以更准确地评估边界框之间的距离。使用 GIoU 作为回归损失函数可以提高模型的精度。</li><li>限制正样本在 ground-truth 区域内：在训练过程中，限制正样本在 ground-truth 区域内可以更好地训练模型，避免正样本落在背景区域。</li><li>引入 centerness 分支：centerness 是指目标中心点与边界框中心点之间的距离，引入 centerness 分支可以更好地度量目标的位置。</li><li>添加每个级别的特征金字塔的可训练标量：为每个级别的特征金字塔添加可训练标量可以提高模型的表现能力。</li></ol><p>综上所述，这些改进方法可以显著提高目标检测模型的性能，从而缩小锚点型检测器和非锚点型检测器之间的差距。</p><p><h2>十五、spatial and scale dimension </h2><br>在目标检测中，一张图像通常会被分成多个区域，每个区域都会被生成多个大小不同、长宽比不同的 anchor boxes。空间维度指的是这些区域，尺度维度指的是不同大小、长宽比的 anchor boxes。</p><p><h2>十六、ATSS中的超参数k是什么意思 </h2><br>在 ATSS 算法中，超参数 k 表示需要选择多少个与目标框的重叠度最高的锚框作为正样本。具体来说，对于每个目标框，ATSS 算法会计算其与所有锚框的 IoU 值，然后根据这些 IoU 值从高到低排序，并选择与目标框 IoU 最高的前 k 个锚框作为正样本。k 是一个预先设定的常数值。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2&gt;一、FPN&lt;/h2&gt;
FPN是特征金字塔网络（Feature Pyramid Network）的缩写，是一种用于目标检测的深度学习模型。相较于传统的卷积神经网络（CNN），FPN的最大特点在于它可以生成不同尺度的特征金字塔，为检测不同大小物体提供支持。

FPN模型在目标</summary>
      
    
    
    
    <category term="计算机视觉" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="目标检测" scheme="http://example.com/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"/>
    
    <category term="计算机视觉" scheme="http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
  </entry>
  
  <entry>
    <title>SDE求解</title>
    <link href="http://example.com/2023/03/15/Diffusion%20-%20%E5%89%AF%E6%9C%AC%20(3)/"/>
    <id>http://example.com/2023/03/15/Diffusion%20-%20%E5%89%AF%E6%9C%AC%20(3)/</id>
    <published>2023-03-14T16:00:00.000Z</published>
    <updated>2023-05-06T15:18:44.337Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://s2.loli.net/2023/05/06/pldDhQfv1eX5NrI.jpg" alt="扫描全能王 2023-05-06 23.12_1.jpg"></p><p><img src="https://s2.loli.net/2023/05/06/oxiE3I6zm9gF5aS.jpg" alt="扫描全能王 2023-05-06 23.12_2.jpg"></p><p><img src="https://s2.loli.net/2023/05/06/AnqSxRZIBhOVUKN.jpg" alt=""></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;img src=&quot;https://s2.loli.net/2023/05/06/pldDhQfv1eX5NrI.jpg&quot; alt=&quot;扫描全能王 2023-05-06 23.12_1.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://s2.loli.net/20</summary>
      
    
    
    
    <category term="Diffusion" scheme="http://example.com/categories/Diffusion/"/>
    
    
    <category term="Diffusion" scheme="http://example.com/tags/Diffusion/"/>
    
  </entry>
  
  <entry>
    <title>DDIM</title>
    <link href="http://example.com/2023/03/10/Diffusion%20-%20%E5%89%AF%E6%9C%AC%20(2)/"/>
    <id>http://example.com/2023/03/10/Diffusion%20-%20%E5%89%AF%E6%9C%AC%20(2)/</id>
    <published>2023-03-09T16:00:00.000Z</published>
    <updated>2023-05-06T15:16:48.148Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://s2.loli.net/2023/05/06/y5cFZKpUETj2wkP.jpg" alt="扫描全能王 2023-05-06 21.55_4.jpg"></p><p><img src="https://s2.loli.net/2023/05/06/apkNQ3vxnuLjtWo.jpg" alt="扫描全能王 2023-05-06 21.55_5.jpg"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;img src=&quot;https://s2.loli.net/2023/05/06/y5cFZKpUETj2wkP.jpg&quot; alt=&quot;扫描全能王 2023-05-06 21.55_4.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://s2.loli.net/20</summary>
      
    
    
    
    <category term="Diffusion" scheme="http://example.com/categories/Diffusion/"/>
    
    
    <category term="Diffusion" scheme="http://example.com/tags/Diffusion/"/>
    
  </entry>
  
  <entry>
    <title>Diffusion (贝叶斯)</title>
    <link href="http://example.com/2023/03/10/Diffusion%20-%20%E5%89%AF%E6%9C%AC/"/>
    <id>http://example.com/2023/03/10/Diffusion%20-%20%E5%89%AF%E6%9C%AC/</id>
    <published>2023-03-09T16:00:00.000Z</published>
    <updated>2023-05-06T14:13:26.060Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://s2.loli.net/2023/05/06/OVnQ94CUDc8sxhK.jpg" alt="扫描全能王 2023-05-06 21.55_2.jpg"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;img src=&quot;https://s2.loli.net/2023/05/06/OVnQ94CUDc8sxhK.jpg&quot; alt=&quot;扫描全能王 2023-05-06 21.55_2.jpg&quot;&gt;&lt;/p&gt;
</summary>
      
    
    
    
    <category term="Diffusion" scheme="http://example.com/categories/Diffusion/"/>
    
    
    <category term="Diffusion" scheme="http://example.com/tags/Diffusion/"/>
    
  </entry>
  
  <entry>
    <title>Diffusion （拆楼建楼）</title>
    <link href="http://example.com/2023/03/08/Diffusion/"/>
    <id>http://example.com/2023/03/08/Diffusion/</id>
    <published>2023-03-07T16:00:00.000Z</published>
    <updated>2023-05-06T14:12:07.297Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://s2.loli.net/2023/05/06/dmOEHuNVz2KYnLc.jpg" alt="扫描全能王 2023-05-06 21.55_1.jpg"></p><p><img src="https://s2.loli.net/2023/05/06/HfTnkoX3BdP2ryO.jpg" alt="扫描全能王 2023-05-06 21.55_3.jpg"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;img src=&quot;https://s2.loli.net/2023/05/06/dmOEHuNVz2KYnLc.jpg&quot; alt=&quot;扫描全能王 2023-05-06 21.55_1.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://s2.loli.net/20</summary>
      
    
    
    
    <category term="Diffusion" scheme="http://example.com/categories/Diffusion/"/>
    
    
    <category term="Diffusion" scheme="http://example.com/tags/Diffusion/"/>
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/2023/03/04/%E7%AE%97%E6%B3%953/"/>
    <id>http://example.com/2023/03/04/%E7%AE%97%E6%B3%953/</id>
    <published>2023-03-03T16:22:03.298Z</published>
    <updated>2023-03-03T16:30:10.764Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">//快速排序</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">quick_sort</span><span class="params">(<span class="type">int</span> q[], <span class="type">int</span> l, <span class="type">int</span> r)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (l &gt;= r) <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> i = l - <span class="number">1</span>, j = r + <span class="number">1</span>, x = q[l + r &gt;&gt; <span class="number">1</span>];</span><br><span class="line">    <span class="keyword">while</span> (i &lt; j)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">do</span> i ++ ; <span class="keyword">while</span> (q[i] &lt; x);</span><br><span class="line">        <span class="keyword">do</span> j -- ; <span class="keyword">while</span> (q[j] &gt; x);</span><br><span class="line">        <span class="keyword">if</span> (i &lt; j) <span class="built_in">swap</span>(q[i], q[j]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">quick_sort</span>(q, l, j), <span class="built_in">quick_sort</span>(q, j + <span class="number">1</span>, r);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//归并排序</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">merge_sort</span><span class="params">(<span class="type">int</span> q[], <span class="type">int</span> l, <span class="type">int</span> r)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (l &gt;= r) <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> mid = l + r &gt;&gt; <span class="number">1</span>;</span><br><span class="line">    <span class="built_in">merge_sort</span>(q, l, mid);</span><br><span class="line">    <span class="built_in">merge_sort</span>(q, mid + <span class="number">1</span>, r);</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> k = <span class="number">0</span>, i = l, j = mid + <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span> (i &lt;= mid &amp;&amp; j &lt;= r)</span><br><span class="line">        <span class="keyword">if</span> (q[i] &lt;= q[j]) tmp[k ++ ] = q[i ++ ];</span><br><span class="line">        <span class="keyword">else</span> tmp[k ++ ] = q[j ++ ];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (i &lt;= mid) tmp[k ++ ] = q[i ++ ];</span><br><span class="line">    <span class="keyword">while</span> (j &lt;= r) tmp[k ++ ] = q[j ++ ];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (i = l, j = <span class="number">0</span>; i &lt;= r; i ++, j ++ ) q[i] = tmp[j];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//整数二分算法</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">check</span><span class="params">(<span class="type">int</span> x)</span> </span>&#123;<span class="comment">/* ... */</span>&#125; <span class="comment">// 检查x是否满足某种性质</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 区间[l, r]被划分成[l, mid]和[mid + 1, r]时使用：</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">bsearch_1</span><span class="params">(<span class="type">int</span> l, <span class="type">int</span> r)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (l &lt; r)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> mid = l + r &gt;&gt; <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">check</span>(mid)) r = mid;    <span class="comment">// check()判断mid是否满足性质</span></span><br><span class="line">        <span class="keyword">else</span> l = mid + <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> l;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 区间[l, r]被划分成[l, mid - 1]和[mid, r]时使用：</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">bsearch_2</span><span class="params">(<span class="type">int</span> l, <span class="type">int</span> r)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (l &lt; r)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> mid = l + r + <span class="number">1</span> &gt;&gt; <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">check</span>(mid)) l = mid;</span><br><span class="line">        <span class="keyword">else</span> r = mid - <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> l;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//浮点数二分算法</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">check</span><span class="params">(<span class="type">double</span> x)</span> </span>&#123;<span class="comment">/* ... */</span>&#125; <span class="comment">// 检查x是否满足某种性质</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">double</span> <span class="title">bsearch_3</span><span class="params">(<span class="type">double</span> l, <span class="type">double</span> r)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">double</span> eps = <span class="number">1e-6</span>;   <span class="comment">// eps 表示精度，取决于题目对精度的要求</span></span><br><span class="line">    <span class="keyword">while</span> (r - l &gt; eps)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">double</span> mid = (l + r) / <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">check</span>(mid)) r = mid;</span><br><span class="line">        <span class="keyword">else</span> l = mid;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> l;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//高精度加法</span></span><br><span class="line"><span class="comment">// C = A + B, A &gt;= 0, B &gt;= 0</span></span><br><span class="line"><span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">add</span><span class="params">(vector&lt;<span class="type">int</span>&gt; &amp;A, vector&lt;<span class="type">int</span>&gt; &amp;B)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (A.<span class="built_in">size</span>() &lt; B.<span class="built_in">size</span>()) <span class="keyword">return</span> <span class="built_in">add</span>(B, A);</span><br><span class="line"></span><br><span class="line">    vector&lt;<span class="type">int</span>&gt; C;</span><br><span class="line">    <span class="type">int</span> t = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; A.<span class="built_in">size</span>(); i ++ )</span><br><span class="line">    &#123;</span><br><span class="line">        t += A[i];</span><br><span class="line">        <span class="keyword">if</span> (i &lt; B.<span class="built_in">size</span>()) t += B[i];</span><br><span class="line">        C.<span class="built_in">push_back</span>(t % <span class="number">10</span>);</span><br><span class="line">        t /= <span class="number">10</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (t) C.<span class="built_in">push_back</span>(t);</span><br><span class="line">    <span class="keyword">return</span> C;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//高精度减法</span></span><br><span class="line"><span class="comment">// C = A - B, 满足A &gt;= B, A &gt;= 0, B &gt;= 0</span></span><br><span class="line"><span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">sub</span><span class="params">(vector&lt;<span class="type">int</span>&gt; &amp;A, vector&lt;<span class="type">int</span>&gt; &amp;B)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    vector&lt;<span class="type">int</span>&gt; C;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>, t = <span class="number">0</span>; i &lt; A.<span class="built_in">size</span>(); i ++ )</span><br><span class="line">    &#123;</span><br><span class="line">        t = A[i] - t;</span><br><span class="line">        <span class="keyword">if</span> (i &lt; B.<span class="built_in">size</span>()) t -= B[i];</span><br><span class="line">        C.<span class="built_in">push_back</span>((t + <span class="number">10</span>) % <span class="number">10</span>);</span><br><span class="line">        <span class="keyword">if</span> (t &lt; <span class="number">0</span>) t = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">else</span> t = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (C.<span class="built_in">size</span>() &gt; <span class="number">1</span> &amp;&amp; C.<span class="built_in">back</span>() == <span class="number">0</span>) C.<span class="built_in">pop_back</span>();</span><br><span class="line">    <span class="keyword">return</span> C;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//高精度乘低精度</span></span><br><span class="line"><span class="comment">// C = A * b, A &gt;= 0, b &gt;= 0</span></span><br><span class="line"><span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">mul</span><span class="params">(vector&lt;<span class="type">int</span>&gt; &amp;A, <span class="type">int</span> b)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    vector&lt;<span class="type">int</span>&gt; C;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> t = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; A.<span class="built_in">size</span>() || t; i ++ )</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (i &lt; A.<span class="built_in">size</span>()) t += A[i] * b;</span><br><span class="line">        C.<span class="built_in">push_back</span>(t % <span class="number">10</span>);</span><br><span class="line">        t /= <span class="number">10</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (C.<span class="built_in">size</span>() &gt; <span class="number">1</span> &amp;&amp; C.<span class="built_in">back</span>() == <span class="number">0</span>) C.<span class="built_in">pop_back</span>();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> C;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">作者：yxc</span><br><span class="line">链接：https:<span class="comment">//www.acwing.com/blog/content/277/</span></span><br><span class="line">来源：AcWing</span><br><span class="line">著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//高精度除以低精度</span></span><br><span class="line"><span class="comment">// A / b = C ... r, A &gt;= 0, b &gt; 0</span></span><br><span class="line"><span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">div</span><span class="params">(vector&lt;<span class="type">int</span>&gt; &amp;A, <span class="type">int</span> b, <span class="type">int</span> &amp;r)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    vector&lt;<span class="type">int</span>&gt; C;</span><br><span class="line">    r = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = A.<span class="built_in">size</span>() - <span class="number">1</span>; i &gt;= <span class="number">0</span>; i -- )</span><br><span class="line">    &#123;</span><br><span class="line">        r = r * <span class="number">10</span> + A[i];</span><br><span class="line">        C.<span class="built_in">push_back</span>(r / b);</span><br><span class="line">        r %= b;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">reverse</span>(C.<span class="built_in">begin</span>(), C.<span class="built_in">end</span>());</span><br><span class="line">    <span class="keyword">while</span> (C.<span class="built_in">size</span>() &gt; <span class="number">1</span> &amp;&amp; C.<span class="built_in">back</span>() == <span class="number">0</span>) C.<span class="built_in">pop_back</span>();</span><br><span class="line">    <span class="keyword">return</span> C;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">作者：yxc</span><br><span class="line">链接：https:<span class="comment">//www.acwing.com/blog/content/277/</span></span><br><span class="line">来源：AcWing</span><br><span class="line">著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//一维前缀和</span></span><br><span class="line">S[i] = a[<span class="number">1</span>] + a[<span class="number">2</span>] + ... a[i]</span><br><span class="line">a[l] + ... + a[r] = S[r] - S[l - <span class="number">1</span>]</span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//二维前缀和</span></span><br><span class="line">S[i, j] = 第i行j列格子左上部分所有元素的和</span><br><span class="line">以(x1, y1)为左上角，(x2, y2)为右下角的子矩阵的和为：</span><br><span class="line">S[x2, y2] - S[x1 - <span class="number">1</span>, y2] - S[x2, y1 - <span class="number">1</span>] + S[x1 - <span class="number">1</span>, y1 - <span class="number">1</span>]</span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//一维差分</span></span><br><span class="line">给区间[l, r]中的每个数加上c：B[l] += c, B[r + <span class="number">1</span>] -= c</span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//二维差分</span></span><br><span class="line">给以(x1, y1)为左上角，(x2, y2)为右下角的子矩阵中的所有元素加上c：</span><br><span class="line">S[x1, y1] += c, S[x2 + <span class="number">1</span>, y1] -= c, S[x1, y2 + <span class="number">1</span>] -= c, S[x2 + <span class="number">1</span>, y2 + <span class="number">1</span>] += c</span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//位运算</span></span><br><span class="line">求n的第k位数字: n &gt;&gt; k &amp; <span class="number">1</span></span><br><span class="line">返回n的最后一位<span class="number">1</span>：<span class="built_in">lowbit</span>(n) = n &amp; -n</span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//双指针算法</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>, j = <span class="number">0</span>; i &lt; n; i ++ )</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">while</span> (j &lt; i &amp;&amp; <span class="built_in">check</span>(i, j)) j ++ ;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 具体问题的逻辑</span></span><br><span class="line">&#125;</span><br><span class="line">常见问题分类：</span><br><span class="line">    (<span class="number">1</span>) 对于一个序列，用两个指针维护一段区间</span><br><span class="line">    (<span class="number">2</span>) 对于两个序列，维护某种次序，比如归并排序中合并两个有序序列的操作</span><br></pre></td></tr></table></figure><p>作者：yxc<br>链接：<a href="https://www.acwing.com/blog/content/277/">https://www.acwing.com/blog/content/277/</a><br>来源：AcWing</p>]]></content>
    
    
      
      
    <summary type="html">&lt;figure class=&quot;highlight c++&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Attention学习机制数学推导</title>
    <link href="http://example.com/2023/03/02/Attention%E5%AD%A6%E4%B9%A0%E6%9C%BA%E5%88%B6%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/"/>
    <id>http://example.com/2023/03/02/Attention%E5%AD%A6%E4%B9%A0%E6%9C%BA%E5%88%B6%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/</id>
    <published>2023-03-01T16:16:41.922Z</published>
    <updated>2023-05-02T17:48:06.731Z</updated>
    
    <content type="html"><![CDATA[<p>注意力机制是一种在深度学习中常用的机制，可以在处理变长输入序列时，让模型更加关注与当前任务相关的信息。下面是注意力机制的数学证明。</p><p>假设我们有一个输入序列$x = (x_1, x_2, …, x_T)$，其中每个$x_t$都是一个向量，$y$是输出序列。我们需要在每个时间步$t$选择适当的$x_t$来计算$y_t$。注意力机制的思想是，对于每个时间步$t$，我们计算出$x_t$和所有$x_i$之间的相似度得分，然后根据这些得分来给每个$x_i$分配一个权重，最终使用加权平均的方法来计算$y_t$。</p><p>具体来说，我们可以使用一个查询向量$q_t$来度量$x_t$和所有$x_i$之间的相似度。一种常用的计算方式是点积计算：</p><script type="math/tex; mode=display">\text{score}(q_t, x_i) = q_t^Tx_i</script><p>接着，我们可以将得分进行归一化，得到一个权重向量$\alpha<em>t$，其中$\alpha</em>{t,i}$表示在计算$y_t$时应该分配给$x_i$的权重：</p><script type="math/tex; mode=display">\alpha_{t,i} = \frac{\exp(\text{score}(q_t, x_i))}{\sum_{j=1}^{T}\exp(\text{score}(q_t, x_j))}</script><p>最后，我们可以使用加权平均的方法来计算$y_t$：</p><script type="math/tex; mode=display">y_t = \sum_{i=1}^{T}\alpha_{t,i}x_i</script><p>注意力机制的数学证明主要是通过反向传播算法来训练模型。假设$L$是损失函数，我们需要计算$L$对$q_t$和$x_i$的梯度。根据链式法则，我们可以将$L$对$x_i$的梯度表示为：</p><script type="math/tex; mode=display">\frac{\partial L}{\partial x_i} = \sum_{t=1}^{T}\frac{\partial L}{\partial y_t}\alpha_{t,i}</script><p>这意味着，对于每个$x_i$，我们可以通过对所有$y_t$进行加权求和，来计算$L$对$x_i$的梯度。类似地，我们可以将$L$对$q_t$的梯度表示为：</p><script type="math/tex; mode=display">\frac{\partial L}{\partial q_t} = \sum_{i=1}^{T}\frac{\partial L}{\partial y_t}\frac{\partial y_t}{\partial \alpha_{t,i}}\frac{\partial \alpha_{t,i}}{\partial q_t}</script><p>其中，$\frac{\partial y<em>t}{\partial \alpha</em>{t,i}}$表示$y<em>t$对$\alpha</em>{t,i}$的梯度，可以通过链式法则计算得出：</p><script type="math/tex; mode=display">\frac{\partial y_t}{\partial \alpha_{t,i}} = x_i</script><p>$\frac{\partial \alpha_{t,i}}{\partial q_t}$表示$\</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;注意力机制是一种在深度学习中常用的机制，可以在处理变长输入序列时，让模型更加关注与当前任务相关的信息。下面是注意力机制的数学证明。&lt;/p&gt;
&lt;p&gt;假设我们有一个输入序列$x = (x_1, x_2, …, x_T)$，其中每个$x_t$都是一个向量，$y$是输出序列。我们需</summary>
      
    
    
    
    <category term="RNN  VS  Transformer" scheme="http://example.com/categories/RNN-VS-Transformer/"/>
    
    
    <category term="Paper" scheme="http://example.com/tags/Paper/"/>
    
  </entry>
  
  <entry>
    <title>基础算法之排序</title>
    <link href="http://example.com/2023/01/17/%E7%AE%97%E6%B3%95/"/>
    <id>http://example.com/2023/01/17/%E7%AE%97%E6%B3%95/</id>
    <published>2023-01-17T12:10:00.000Z</published>
    <updated>2023-01-17T12:23:46.415Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//快排</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">quick_sort</span><span class="params">(<span class="type">int</span> q[],<span class="type">int</span> l,<span class="type">int</span> r)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(l&gt;=r)<span class="keyword">return</span>;</span><br><span class="line">    <span class="type">int</span> i=l<span class="number">-1</span>,j=r+<span class="number">1</span>,x=q[i+j&gt;&gt;<span class="number">1</span>];</span><br><span class="line">    <span class="keyword">while</span>(i&lt;j)&#123;</span><br><span class="line">        <span class="keyword">do</span> i++;<span class="keyword">while</span>(x&gt;q[i]);</span><br><span class="line">        <span class="keyword">do</span> j--;<span class="keyword">while</span>(x&lt;q[j]);</span><br><span class="line">        <span class="keyword">if</span>(i&lt;j)<span class="built_in">swap</span>(q[i],q[j]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">quick_sort</span>(q,l,j);</span><br><span class="line">    <span class="built_in">quick_sort</span>(q,j+<span class="number">1</span>,r);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//归并排序</span></span><br><span class="line"><span class="type">int</span> tmp[];</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">merge_sort</span><span class="params">(<span class="type">int</span> q[],<span class="type">int</span> l,<span class="type">int</span> r)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(l&gt;=r)<span class="keyword">return</span>;</span><br><span class="line">    <span class="type">int</span> mid = l+r&gt;&gt;<span class="number">1</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">merge_sort</span>(q,l,mid);</span><br><span class="line">    <span class="built_in">merge_sort</span>(q,mid+<span class="number">1</span>,r);</span><br><span class="line">    </span><br><span class="line">    <span class="type">int</span> k=<span class="number">0</span>,i=l,j=mid+<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span>(i&lt;= mid &amp;&amp; j&lt;=r)&#123;</span><br><span class="line">        <span class="keyword">if</span>(q[i]&lt;=q[j])tmp[k++]=q[i++];</span><br><span class="line">        <span class="keyword">else</span> tmp[k++]=q[j++];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">while</span> (i&lt;=mid)tmp[k++]=q[i++];</span><br><span class="line">    <span class="keyword">while</span> (j&lt;=r)tmp[k++]=q[j++];</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=l,j=<span class="number">0</span>;i&lt;=r;i++,j++)q[i]=tmp[j];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;figure class=&quot;highlight c++&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;</summary>
      
    
    
    
    <category term="算法" scheme="http://example.com/categories/%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="快排" scheme="http://example.com/tags/%E5%BF%AB%E6%8E%92/"/>
    
    <category term="归并" scheme="http://example.com/tags/%E5%BD%92%E5%B9%B6/"/>
    
  </entry>
  
  <entry>
    <title>基础算法之高精度加减乘除法</title>
    <link href="http://example.com/2023/01/17/%E7%AE%97%E6%B3%952/"/>
    <id>http://example.com/2023/01/17/%E7%AE%97%E6%B3%952/</id>
    <published>2023-01-17T12:10:00.000Z</published>
    <updated>2023-01-18T15:17:40.266Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">高精度加法</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">add</span><span class="params">(vector&lt;<span class="type">int</span>&gt; A, vector&lt;<span class="type">int</span>&gt; B)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (A.<span class="built_in">size</span>() &lt; B.<span class="built_in">size</span>()) <span class="keyword">return</span> <span class="built_in">add</span>(B, A);</span><br><span class="line"></span><br><span class="line">    vector&lt;<span class="type">int</span>&gt; C;</span><br><span class="line">    <span class="type">int</span> t = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; A.<span class="built_in">size</span>(); i ++ )</span><br><span class="line">    &#123;</span><br><span class="line">        t += A[i];</span><br><span class="line">        <span class="keyword">if</span> (i &lt; B.<span class="built_in">size</span>()) t += B[i];</span><br><span class="line">        C.<span class="built_in">push_back</span>(t % <span class="number">10</span>);</span><br><span class="line">        t /= <span class="number">10</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (t) C.<span class="built_in">push_back</span>(t);</span><br><span class="line">    <span class="keyword">return</span> C;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    string a , b;</span><br><span class="line">    vector&lt;<span class="type">int</span>&gt;A,B;</span><br><span class="line">    cin&gt;&gt;a&gt;&gt;b;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i =a.<span class="built_in">size</span>()<span class="number">-1</span>;i&gt;=<span class="number">0</span>;i--)&#123;</span><br><span class="line">        A.<span class="built_in">push_back</span>(a[i]-<span class="string">&#x27;0&#x27;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i =b.<span class="built_in">size</span>()<span class="number">-1</span>;i&gt;=<span class="number">0</span>;i--)&#123;</span><br><span class="line">        B.<span class="built_in">push_back</span>(b[i]-<span class="string">&#x27;0&#x27;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">auto</span> C=<span class="built_in">add</span>(A,B);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i =C.<span class="built_in">size</span>()<span class="number">-1</span>;i&gt;=<span class="number">0</span>;i--)<span class="built_in">printf</span>(<span class="string">&quot;%d&quot;</span>,C[i]);</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">高精度减法</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="comment">//A&gt;=B ?</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">cmp</span><span class="params">(string a,string b)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(a.<span class="built_in">size</span>()!=b.<span class="built_in">size</span>())<span class="keyword">return</span> a.<span class="built_in">size</span>()&gt;b.<span class="built_in">size</span>();</span><br><span class="line">    <span class="keyword">else</span>&#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;a.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(a[i]!=b[i])&#123;</span><br><span class="line">                <span class="keyword">return</span> a[i]&gt;b[i];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line">vector &lt;<span class="type">int</span>&gt; <span class="built_in">sub</span>(vector&lt;<span class="type">int</span>&gt; &amp;A,vector&lt;<span class="type">int</span>&gt; &amp;B)&#123;</span><br><span class="line">    <span class="type">int</span> t=<span class="number">0</span>;</span><br><span class="line">    vector &lt;<span class="type">int</span>&gt;C;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;A.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">        t=A[i]-t;</span><br><span class="line">        <span class="keyword">if</span>(i&lt;B.<span class="built_in">size</span>())t=t-B[i];</span><br><span class="line">        C.<span class="built_in">push_back</span>((t+<span class="number">10</span>)%<span class="number">10</span>);</span><br><span class="line">        <span class="keyword">if</span>(t&lt;<span class="number">0</span>)t=<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">else</span> t=<span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">while</span>(C.<span class="built_in">size</span>()!=<span class="number">1</span> &amp;&amp; C.<span class="built_in">back</span>()==<span class="number">0</span>)C.<span class="built_in">pop_back</span>();</span><br><span class="line">    <span class="keyword">return</span> C;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    string a,b;</span><br><span class="line">    cin&gt;&gt;a&gt;&gt;b;</span><br><span class="line">    vector &lt;<span class="type">int</span>&gt;A,B;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=a.<span class="built_in">size</span>()<span class="number">-1</span>;i&gt;=<span class="number">0</span>;i--)A.<span class="built_in">push_back</span>(a[i]-<span class="string">&#x27;0&#x27;</span>);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=b.<span class="built_in">size</span>()<span class="number">-1</span>;i&gt;=<span class="number">0</span>;i--)B.<span class="built_in">push_back</span>(b[i]-<span class="string">&#x27;0&#x27;</span>);</span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">cmp</span>(a,b))&#123;</span><br><span class="line">        <span class="keyword">auto</span> C=<span class="built_in">sub</span>(A,B);</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=C.<span class="built_in">size</span>()<span class="number">-1</span>;i&gt;=<span class="number">0</span>;i--)cout&lt;&lt;C[i];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span>&#123;</span><br><span class="line">        <span class="keyword">auto</span> C=<span class="built_in">sub</span>(B,A);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;-&quot;</span>);</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=C.<span class="built_in">size</span>()<span class="number">-1</span>;i&gt;=<span class="number">0</span>;i--)cout&lt;&lt;C[i];</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;figure class=&quot;highlight c++&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;</summary>
      
    
    
    
    <category term="算法" scheme="http://example.com/categories/%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="高精度运算" scheme="http://example.com/tags/%E9%AB%98%E7%B2%BE%E5%BA%A6%E8%BF%90%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>基础算法之二分</title>
    <link href="http://example.com/2023/01/17/%E7%AE%97%E6%B3%951/"/>
    <id>http://example.com/2023/01/17/%E7%AE%97%E6%B3%951/</id>
    <published>2023-01-17T12:10:00.000Z</published>
    <updated>2023-01-17T14:10:37.314Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">check</span><span class="params">(<span class="type">int</span> x)</span> </span>&#123;<span class="comment">/* ... */</span>&#125; <span class="comment">// 检查x是否满足某种性质</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//两种整数二分方法</span></span><br><span class="line"><span class="comment">// 区间[l, r]被划分成[l, mid]和[mid + 1, r]时使用：</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">bsearch_1</span><span class="params">(<span class="type">int</span> l, <span class="type">int</span> r)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (l &lt; r)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> mid = l + r &gt;&gt; <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">check</span>(mid)) r = mid;    <span class="comment">// check()判断mid是否满足性质</span></span><br><span class="line">        <span class="keyword">else</span> l = mid + <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> l;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 区间[l, r]被划分成[l, mid - 1]和[mid, r]时使用：</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">bsearch_2</span><span class="params">(<span class="type">int</span> l, <span class="type">int</span> r)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (l &lt; r)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> mid = l + r + <span class="number">1</span> &gt;&gt; <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">check</span>(mid)) l = mid;</span><br><span class="line">        <span class="keyword">else</span> r = mid - <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> l;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//浮点数二分</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">check</span><span class="params">(<span class="type">double</span> x)</span> </span>&#123;<span class="comment">/* ... */</span>&#125; <span class="comment">// 检查x是否满足某种性质</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">double</span> <span class="title">bsearch_3</span><span class="params">(<span class="type">double</span> l, <span class="type">double</span> r)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">double</span> eps = <span class="number">1e-6</span>;   <span class="comment">// eps 表示精度，取决于题目对精度的要求</span></span><br><span class="line">    <span class="keyword">while</span> (r - l &gt; eps)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">double</span> mid = (l + r) / <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">check</span>(mid)) r = mid;</span><br><span class="line">        <span class="keyword">else</span> l = mid;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> l;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;figure class=&quot;highlight c++&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;</summary>
      
    
    
    
    <category term="算法" scheme="http://example.com/categories/%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="整数二分" scheme="http://example.com/tags/%E6%95%B4%E6%95%B0%E4%BA%8C%E5%88%86/"/>
    
    <category term="浮点数二分" scheme="http://example.com/tags/%E6%B5%AE%E7%82%B9%E6%95%B0%E4%BA%8C%E5%88%86/"/>
    
  </entry>
  
  <entry>
    <title>Kullback-Leibler(KL)散度</title>
    <link href="http://example.com/2022/12/30/KL%E6%95%A3%E5%BA%A6/"/>
    <id>http://example.com/2022/12/30/KL%E6%95%A3%E5%BA%A6/</id>
    <published>2022-12-29T16:00:00.000Z</published>
    <updated>2023-02-23T11:11:35.070Z</updated>
    
    <content type="html"><![CDATA[<h1><font face='楷体'>1.概要</font></h1><h3><font face='楷体'>在这篇文章中，将探讨一种比较两个概率分布的方法，称为Kullback-Leibler散度(通常简称为KL散度)。通常在概率和统计中，我们会用更简单的近似分布来代替观察到的数据或复杂的分布。KL散度帮助我们衡量在选择近似值时损失了多少信息。</font></h3><h1><font face='楷体'>2.公式</font></h1><h3><font face='楷体'>KL散度起源于信息论。信息论的主要目标是量化数据中有多少信息。信息论中最重要的指标称为熵，通常表示为H。概率分布的熵的定义是：</font></h3>$$H=-\sum_{i=0}^nlogp(x_i)$$<h3><font face='楷体'>如果在我们的计算中我们使用log2，我们可以把熵解释为“我们编码信息所需要的最小比特数”。在这种情况下，根据我们的经验分布，信息将是每个牙齿计数的观察结果。根据我们观察到的数据，我们的概率分布的熵为3.12比特。比特的数目告诉我们，在单一情况下，我们平均需要多少比特来编码我们将观察到的牙齿数目。</font></h3><h3><font face='楷体'>熵没有告诉我们可以实现这种压缩的最佳编码方案。信息的最佳编码是一个非常有趣的主题，但对于理解KL散度而言不是必需的。熵的关键在于，只要知道所需位数的理论下限，我们就可以准确地量化数据中有多少信息。现在我们可以对此进行量化，当我们将观察到的分布替换为参数化的近似值时，我们丢失了多少信息。</font></h3><h1><font face='楷体'>使用KL散度测量丢失的信息</font></h1><h3><font face='楷体'>Kullback-Leibler散度只是对我们的熵公式的略微修改。不仅仅是有我们的概率分布p，还有上近似分布q。然后，我们查看每个log值的差异：</font></h3><script type="math/tex; mode=display">D_{KL}(p||q)=\sum_{i=1}^Np(x_i)(log\frac{p(x_i)}{q(x_i)})</script><h3><font face='楷体'>本质上，我们用KL散度看的是对原始分布中的数据概率与近似分布之间的对数差的期望。再说一次，如果我们考虑log2，我们可以将其解释为“我们预计有多少比特位的信息丢失”。我们可以根据期望重写公式：</font></h3><script type="math/tex; mode=display">D_{KL}(p||q)=E[log\frac{p(x_i)}{q(x_i)}]</script><h3><font face='楷体'>利用KL散度，我们可以精确地计算出当我们近似一个分布与另一个分布时损失了多少信息。</font></h3><h1><font face='楷体'>3.注意:KL散度不是距离</font></h1><h3><font face='楷体'>将KL散度视为距离度量可能很诱人，但是我们不能使用KL散度来测量两个分布之间的距离。这是因为KL散度不是对称的。</font></h3>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;&lt;font face=&#39;楷体&#39;&gt;1.概要&lt;/font&gt;&lt;/h1&gt;
&lt;h3&gt;&lt;font face=&#39;楷体&#39;&gt;在这篇文章中，将探讨一种比较两个概率分布的方法，称为Kullback-Leibler散度(通常简称为KL散度)。通常在概率和统计中，我们会用更简单的近似分布来代替观察</summary>
      
    
    
    
    <category term="机器学习" scheme="http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="机器学习" scheme="http://example.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>RNN数学推导</title>
    <link href="http://example.com/2022/12/10/RNN%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/"/>
    <id>http://example.com/2022/12/10/RNN%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/</id>
    <published>2022-12-10T13:20:30.000Z</published>
    <updated>2023-05-02T17:48:27.435Z</updated>
    
    <content type="html"><![CDATA[<p>循环神经网络（RNN）是一种特殊类型的神经网络，它在输入之间保持一种状态，并使用该状态来处理序列数据。下面是RNN的数学推导。</p><p>假设我们有一个输入序列$x = (x_1, x_2, …, x_T)$，其中每个$x_t$都是一个向量，$y$是输出序列，$h_t$是RNN在处理$x_t$时的隐藏状态。RNN的隐藏状态$h_t$通过以下递归方式计算：</p><script type="math/tex; mode=display">h_t = f(Ux_t + Wh_{t-1})</script><p>其中，$U$和$W$是权重矩阵，$f$是激活函数，通常是tanh或ReLU。$h_0$通常被初始化为全零向量。</p><p>在计算完所有隐藏状态后，我们可以通过一个输出层来预测输出序列$y$，该输出层可以是全连接层，也可以是softmax层，具体取决于任务的要求。例如，在情感分类任务中，我们可能只需要一个全连接层来预测情感标签。</p><p>输出层的计算方式如下：</p><script type="math/tex; mode=display">y_t = g(Vh_t)</script><p>其中，$V$是权重矩阵，$g$是激活函数。在分类任务中，$g$通常是softmax函数。</p><p>现在我们可以通过反向传播算法来训练RNN，其中损失函数$L$定义为预测输出$y$与实际输出$\hat{y}$之间的交叉熵：</p><script type="math/tex; mode=display">L = -\sum_{t=1}^{T}\hat{y}_t\log(y_t)</script><p>在反向传播过程中，我们需要计算损失函数对权重矩阵$U$、$W$和$V$的梯度。假设$\delta_t$表示损失函数对$h_t$的梯度，则：</p><script type="math/tex; mode=display">\delta_T = \frac{\partial L}{\partial y_T} \odot g'(Vh_T)</script><script type="math/tex; mode=display">\delta_t = \left(\frac{\partial L}{\partial y_t} + \frac{\partial L}{\partial h_{t+1}}\frac{\partial h_{t+1}}{\partial h_t}\right) \odot f'(Ux_t + Wh_{t-1})</script><p>其中，$\odot$表示向量点积，$g’$和$f’$分别是$g$和$f$的导数。我们可以使用这些梯度来更新权重矩阵，例如：</p><script type="math/tex; mode=display">V \leftarrow V - \eta\sum_{t=1}^{T}\delta_t h_t^T</script><script type="math/tex; mode=display">U \leftarrow U - \eta\sum_{t=1}^{T}\delta_t x_t^T</script><script type="math/tex; mode=display">W \leftarrow W - \eta\sum_{t=1}^{T}\delta_t h_{t-1}^T</script><p>其中，$\eta$是学习率。这些更新将使网络逐步调整权重，以最小化损失函数并提高预测精度。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;循环神经网络（RNN）是一种特殊类型的神经网络，它在输入之间保持一种状态，并使用该状态来处理序列数据。下面是RNN的数学推导。&lt;/p&gt;
&lt;p&gt;假设我们有一个输入序列$x = (x_1, x_2, …, x_T)$，其中每个$x_t$都是一个向量，$y$是输出序列，$h_t$</summary>
      
    
    
    
    <category term="RNN  VS  Transformer" scheme="http://example.com/categories/RNN-VS-Transformer/"/>
    
    
    <category term="Paper" scheme="http://example.com/tags/Paper/"/>
    
  </entry>
  
  <entry>
    <title>刷题</title>
    <link href="http://example.com/2022/12/10/%E5%88%B7%E9%A2%98/"/>
    <id>http://example.com/2022/12/10/%E5%88%B7%E9%A2%98/</id>
    <published>2022-12-10T10:27:53.000Z</published>
    <updated>2022-12-09T17:24:24.582Z</updated>
    
    <content type="html"><![CDATA[<p><img src="D:\text\BlogGit\image\1.jpg" alt=""></p><p><img src="D:\text\BlogGit\image\1.1.png" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#include &lt;iostream&gt;</span></span><br><span class="line">using namespace  std;</span><br><span class="line"><span class="built_in">int</span> <span class="type">List</span>[<span class="number">1005</span>][<span class="number">1005</span>];</span><br><span class="line"><span class="built_in">int</span> w[<span class="number">1005</span>];//价值</span><br><span class="line"><span class="built_in">int</span> v[<span class="number">1005</span>];//体积</span><br><span class="line"><span class="built_in">int</span> main() &#123;</span><br><span class="line">    <span class="built_in">int</span> N,V;</span><br><span class="line">    cin&gt;&gt;N&gt;&gt;V;</span><br><span class="line">    w[<span class="number">0</span>]=v[<span class="number">0</span>]=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="built_in">int</span> i=<span class="number">1</span>;i&lt;N+<span class="number">1</span>;i++)&#123;</span><br><span class="line">        cin&gt;&gt;v[i]&gt;&gt;w[i];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span>(<span class="built_in">int</span> i=<span class="number">0</span>;i&lt;N+<span class="number">1</span>;i++)&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="built_in">int</span> j=<span class="number">0</span>;j&lt;V+<span class="number">1</span>;j++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(i==<span class="number">0</span> <span class="keyword">or</span> j==<span class="number">0</span>)&#123;</span><br><span class="line">                <span class="type">List</span>[i][j]=<span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(v[i]&gt;j)&#123;</span><br><span class="line">                <span class="type">List</span>[i][j]=<span class="type">List</span>[i-<span class="number">1</span>][j];</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                <span class="type">List</span>[i][j]=<span class="built_in">max</span>(<span class="type">List</span>[i-<span class="number">1</span>][j],<span class="type">List</span>[i-<span class="number">1</span>][j-v[i]]+w[i]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    cout&lt;&lt;<span class="type">List</span>[N][V];</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="D:\text\BlogGit\image\1.2.png" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#include &lt;iostream&gt;</span></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line"><span class="built_in">int</span> N,V;</span><br><span class="line"><span class="built_in">int</span> v[<span class="number">1010</span>],val[<span class="number">1010</span>];</span><br><span class="line"><span class="built_in">int</span> dp[<span class="number">1010</span>][<span class="number">1010</span>];</span><br><span class="line"><span class="built_in">int</span> main()</span><br><span class="line">&#123;</span><br><span class="line">    scanf(<span class="string">&quot;%d%d&quot;</span>,&amp;N,&amp;V);</span><br><span class="line">    <span class="keyword">for</span>(<span class="built_in">int</span> i=<span class="number">1</span>; i&lt;=N; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        scanf(<span class="string">&quot;%d%d&quot;</span>,&amp;v[i],&amp;val[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span>(<span class="built_in">int</span> i=<span class="number">1</span>; i&lt;=N; i++)</span><br><span class="line">        <span class="keyword">for</span>(<span class="built_in">int</span> j=<span class="number">0</span>; j&lt;=V; j++)</span><br><span class="line">        &#123;</span><br><span class="line">            dp[i][j]=dp[i-<span class="number">1</span>][j];//继承上一个背包</span><br><span class="line">            <span class="keyword">if</span>(j&gt;=v[i])</span><br><span class="line">            &#123;  //完全背包状态转移方程</span><br><span class="line">                dp[i][j]=<span class="built_in">max</span>(dp[i-<span class="number">1</span>][j],dp[i][j-v[i]]+val[i]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    printf(<span class="string">&quot;%d&quot;</span>,dp[N][V]);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="D:\text\BlogGit\image\1.3.png" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#include &lt;iostream&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cstring&gt;</span></span><br><span class="line"></span><br><span class="line">using namespace  std;</span><br><span class="line"><span class="built_in">int</span> <span class="type">List</span>[<span class="number">1005</span>][<span class="number">1005</span>];</span><br><span class="line"><span class="built_in">int</span> w[<span class="number">1005</span>];//价值</span><br><span class="line"><span class="built_in">int</span> v[<span class="number">1005</span>];//体积</span><br><span class="line"><span class="built_in">int</span> s[<span class="number">1005</span>];//件数</span><br><span class="line"><span class="built_in">int</span> N,V;</span><br><span class="line"><span class="built_in">int</span> k;</span><br><span class="line"><span class="built_in">int</span> main() &#123;</span><br><span class="line">    cin&gt;&gt;N&gt;&gt;V;</span><br><span class="line">    w[<span class="number">0</span>]=v[<span class="number">0</span>]=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="built_in">int</span> i=<span class="number">1</span>;i&lt;N+<span class="number">1</span>;i++)&#123;</span><br><span class="line">        scanf(<span class="string">&quot;%d%d%d&quot;</span>,&amp;v[i],&amp;w[i],&amp;s[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    memset(<span class="type">List</span>,<span class="number">0</span>,sizeof(<span class="type">List</span>));</span><br><span class="line">    <span class="keyword">for</span>(<span class="built_in">int</span> i=<span class="number">1</span>;i&lt;N+<span class="number">1</span>;i++)&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="built_in">int</span> j=<span class="number">0</span>;j&lt;V+<span class="number">1</span>;j++)&#123;</span><br><span class="line">            k=<span class="built_in">min</span>(s[i],j/v[i]);</span><br><span class="line">            <span class="keyword">for</span>(<span class="built_in">int</span> t=<span class="number">0</span>;t&lt;=k;t++)&#123;</span><br><span class="line">                <span class="type">List</span>[i][j]= <span class="built_in">max</span>(<span class="type">List</span>[i][j],<span class="type">List</span>[i-<span class="number">1</span>][j-t*v[i]]+t*w[i]);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    cout&lt;&lt;<span class="type">List</span>[N][V];</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;img src=&quot;D:\text\BlogGit\image\1.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;D:\text\BlogGit\image\1.1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight pytho</summary>
      
    
    
    
    <category term="算法刷题" scheme="http://example.com/categories/%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98/"/>
    
    
    <category term="背包问题" scheme="http://example.com/tags/%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/"/>
    
  </entry>
  
  <entry>
    <title>基于大数据方法的豆瓣电影短评分类、预测与搜索（一）</title>
    <link href="http://example.com/2022/11/17/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AF%BC%E8%AE%BA%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1/"/>
    <id>http://example.com/2022/11/17/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AF%BC%E8%AE%BA%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1/</id>
    <published>2022-11-16T16:00:00.000Z</published>
    <updated>2023-03-27T07:06:27.049Z</updated>
    
    <content type="html"><![CDATA[<h3>    综述</h3><p> 链接：<a href="https://pan.baidu.com/s/10DHtZbPnH2SsuaPaZcIuLQ">https://pan.baidu.com/s/10DHtZbPnH2SsuaPaZcIuLQ</a><br>提取码：tf9p</p><p> 目前，大数据越来越多的和人工智能关联起来。而人工智能发展迅猛，在多个领域取得了巨大的成就，比如自然语言处理，图像处理，数据挖掘等。而本文正是诞生在如此环境下。首先本文基于Scrapy框架爬取豆瓣短评数据并进行清洗，然后通过hadoop+spark+mongodb完全分布式部署框架来进行数据的分类与采集，最终我们得到了比例为8:1:1的训练集、测试集和验证集。并在此基础上，我们调用了TextCNN、TextRCNN、TextRNN_Att、FastText、Transformer五大文本分类模型训练豆瓣Top250的短评，最后训练出五个可以通过短评来判断电影种类的模型，我们分别计算这五个模型的各个参数，最终选择一个较好的模型——TextRCNN模型来作为我们的后端模型。我们使用Fastapi来进行前后端分离的web应用。同时，我们在此基础上，为了能够让使用者能够仔细观察一个电影的具体情况，找到自己喜欢的电影，我们建立了基于余弦相似度的搜索模型，达到了模糊搜索的功能，并将其与前端相连，形成我们整个完整的项目。</p><h3>  研究背景</h3><p>目前，大数据越来越多的和人工智能关联起来。而人工智能发展迅猛，在多个领域取得了巨大的成就，比如自然语言处理，图像处理，数据挖掘等。文本挖掘是其中的一个研究方向。根据维基百科的定义，文本挖掘也叫文本数据挖掘，或是文本分析，是从文本中获取高质量信息的过程，典型的任务有文本分类、自动问答、情感分析、机器翻译等。文本分类是将数据分成预先定义好的类别，一般流程为：1. 预处理，比如分词，去掉停用词；2. 文本表示及特征选择；3. 分类器构造；4. 分类器根据文本的特征进行分类；5. 分类结果的评价。&lt;/br&gt;<br>由于近年来人工智能的快速发展，文本分类技术已经可以很好的确定一个未知文档的类别，而且准确度也很好。借助文本分类，可以方便进行海量信息处理，节约大量的信息处理费用。广泛应用于过滤信息，组织与管理信息，数字图书馆、垃圾邮件过滤等社会生活的各个领域。&lt;/br&gt;</p><p>同时，随着网络的发展，电影事业的发展越来越繁荣，其的种类也越来越繁多。目前电影主要可以分为动作、喜剧、犯罪、爱情、科幻、战争等多种类型。而不同类型的电影，读者关于它们的评论却大相径庭。在基于hadoop+spark完全分布式平台的本次项目，我们主要针对于犯罪、喜剧、科幻和战争四种类型差异较大的电影，采用爬虫爬取到的不同类型的电影的影评作为数据集，运用TextCNN、TextRCNN、TextRNN_Att、FastText、Transformer五种文本分类模型来进行训练，最后选取一个预测结果结果最好的模型加载作为我们的fastapi+webUI实现的后端。最后因为电影在大数据报中仅能展示部分，而不能展示其的具体介绍。因此我又打算通过基于余弦相似度的分类算法来做一个小型的搜索系统。&lt;/br&gt;<br>以上就是我项目的研究背景。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3&gt;
    综述
&lt;/h3&gt;

&lt;p&gt; 链接：&lt;a href=&quot;https://pan.baidu.com/s/10DHtZbPnH2SsuaPaZcIuLQ&quot;&gt;https://pan.baidu.com/s/10DHtZbPnH2SsuaPaZcIuLQ&lt;/a&gt;&lt;br&gt;提</summary>
      
    
    
    
    <category term="大数据导论" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AF%BC%E8%AE%BA/"/>
    
    
    <category term="课程设计" scheme="http://example.com/tags/%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>基于大数据方法的豆瓣电影短评分类、预测与搜索（二）:框架介绍</title>
    <link href="http://example.com/2022/11/17/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AF%BC%E8%AE%BA%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A11/"/>
    <id>http://example.com/2022/11/17/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AF%BC%E8%AE%BA%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A11/</id>
    <published>2022-11-16T16:00:00.000Z</published>
    <updated>2023-03-26T15:49:43.317Z</updated>
    
    <content type="html"><![CDATA[<h3>Scrapy框架</h3><p>Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。 可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。</p><p>所谓网络爬虫，就是一个在网上到处或定向抓取数据的程序，当然，这种说法不够专业，更专业的描述就是，抓取特定网站网页的HTML数据。抓取网页的一般方法是，定义一个入口页面，然后一般一个页面会有其他页面的URL，于是从当前页面获取到这些URL加入到爬虫的抓取队列中，然后进入到新页面后再递归的进行上述的操作，其实说来就跟深度遍历或广度遍历一样。</p><p>Scrapy 使用 Twisted这个异步网络库来处理网络通讯，架构清晰，并且包含了各种中间件接口，可以灵活的完成各种需求。</p><h3>Hadoop</h3><h4>背景</h4><p>Hadoop是一个由Apache基金会所开发的<a href="https://baike.baidu.com/item/分布式系统/4905336?fromModule=lemma_inlink">分布式系统</a>基础架构。用户可以在不了解分布式底层细节的情况下，开发分布式程序。充分利用集群的威力进行高速运算和存储。Hadoop实现了一个<a href="https://baike.baidu.com/item/分布式文件系统/1250388?fromModule=lemma_inlink">分布式文件系统</a>（ Distributed File System），其中一个组件是<a href="https://baike.baidu.com/item/HDFS/4836121?fromModule=lemma_inlink">HDFS</a>（Hadoop Distributed File System）。HDFS有高<a href="https://baike.baidu.com/item/容错性/9131391?fromModule=lemma_inlink">容错性</a>的特点，并且设计用来部署在低廉的（low-cost）硬件上；而且它提供高吞吐量（high throughput）来访问<a href="https://baike.baidu.com/item/应用程序/5985445?fromModule=lemma_inlink">应用程序</a>的数据，适合那些有着超大数据集（large data set）的应用程序。HDFS放宽了（relax）<a href="https://baike.baidu.com/item/POSIX/3792413?fromModule=lemma_inlink">POSIX</a>的要求，可以以流的形式访问（streaming access）文件系统中的数据。Hadoop的框架最核心的设计就是：<a href="https://baike.baidu.com/item/HDFS/4836121?fromModule=lemma_inlink">HDFS</a>和<a href="https://baike.baidu.com/item/MapReduce/133425?fromModule=lemma_inlink">MapReduce</a>。HDFS为海量的数据提供了存储，而MapReduce则为海量的数据提供了计算。</p><h4>优点</h4><p>Hadoop是一个能够让用户轻松架构和使用的分布式计算平台。用户可以轻松地在Hadoop上开发和运行处理海量数据的应用程序。它主要有以下几个优点：&lt;/br&gt;<br>1.高可靠性。Hadoop按位存储和处理数据的能力值得人们信赖&lt;/br&gt;。&lt;/br&gt;<br>2.高扩展性。Hadoop是在可用的计算机集簇间分配数据并完成计算任务的，这些集簇可以方便地扩展到数以千计的节点中。&lt;/br&gt;<br>3.高效性。Hadoop能够在节点之间动态地移动数据，并保证各个节点的动态平衡，因此处理速度非常快。&lt;/br&gt;<br>4.高容错性。Hadoop能够自动保存数据的多个副本，并且能够自动将失败的任务重新分配。&lt;/br&gt;<br>5.低成本。与一体机、商用数据仓库以及QlikView、Yonghong Z-Suite等数据集市相比，hadoop是开源的，项目的软件成本因此会大大降低。&lt;/br&gt;<br>Hadoop带有用Java语言编写的框架，因此运行在 Linux 生产平台上是非常理想的。Hadoop 上的应用程序也可以使用其他语言编写，比如C++。</p><h3>Spark </h3><p>   Spark使用Scala语言进行实现，它是一种面向对象、函数式编程语言，能够像操作本地集合对象一样轻松地操作分布式数据集，具有以下特点。<br>1.运行速度快：Spark拥有DAG执行引擎，支持在内存中对数据进行迭代计算。官方提供的数据表明，如果数据由磁盘读取，速度是Hadoop MapReduce的10倍以上，如果数据从内存中读取，速度可以高达100多倍。<br>2.易用性好：Spark不仅支持Scala编写应用程序，而且支持Java和Python等语言进行编写，特别是Scala是一种高效、可拓展的语言，能够用简洁的代码处理较为复杂的处理工作。&lt;/br&gt;<br>3.通用性强：Spark生态圈即BDAS（伯克利数据分析栈）包含了Spark Core、Spark SQL、Spark Streaming、MLLib和GraphX等组件，这些组件分别处理Spark Core提供内存计算框架、SparkStreaming的实时处理应用、Spark SQL的即席查询、MLlib或MLbase的机器学习和GraphX的图处理。<br>4.随处运行：Spark具有很强的适应性，能够读取HDFS、Cassandra、HBase、S3和Techyon为持久层读写原生数据，能够以Mesos、YARN和自身携带的Standalone作为资源管理器调度job，来完成Spark应用程序的计算。</p><h3>Mongodb</h3><h2>背景介绍</h2><p>MongoDB是一个基于分布式文件存储的数据库。</p><p>由C++语言编写，旨在为WEB应用提供可扩展的高性能数据存储解决方案。</p><p>MongoDB是一个介于关系数据库和非关系数据库之间的产品，是非关系数据库当中功能最丰富，最像关系数据库的。</p><p>它支持的数据结构非常松散，是类似json的bson格式，因此可以存储比较复杂的数据类型。</p><p>Mongo最大的特点是它支持的查询语言非常强大，其语法有点类似于面向对象的查询语言，几乎可以实现类似关系数据库单表查询的绝大部分功能，而且还支持对数据建立索引。</p><h2>业务场景</h2><p>传统的关系型数据库(如MySQL)，在数据操作的三高需求以及应对Web2.0的网站需求面前，显得力不从心，而 MongoDB可应对“三高“需求：</p><p>High performance：对数据库高并发读写的需求</p><p>Huge Storage：对海量数据的高效率存储和访问的需求</p><p>High Scalability &amp;&amp; High Availability：对数据库的高可扩展性和高可用性的需求</p><p>具体应用场景：</p><p>社交场景，使用 MongoDB存储存储用户信息，以及用户发表的朋友圈信息，通过地理位置索引实现附近的人、地点等功能。</p><p>游戏场景，使用 MongoDB存储游戏用户信息，用户的装备、积分等直接以内嵌文档的形式存储，方便查询、高效率存储和访问。</p><p>物流场景，使用 MongoDB存储订单信息，订单状态在运送过程中会不断更新，以 MongoDB内嵌数组的形式来存储，一次查询就能将订单所有的变更读取出来</p><p>物联网场景，使用 MongoDB存储所有接入的智能设备信息，以及设备汇报的日志信息，并对这些信息进行多维度的分析。</p><p>视频直播，使用 MongoDB存储用户信息、点赞互动信息等。</p><p>这些应用场景中，数据操作方面的共同特点是：</p><p>（1）数据量大</p><p>（2）写入操作频繁（读写都很频繁）</p><p>（3）价值较低的数据，对事务性要求不高</p><p>对于这样的数据，我们更适合使用 MongoDB来实现数据的存储。</p><h2>特点</h2><p>（1）高性能</p><p>MongoDB提供高性能的数据持久性。特别是，</p><p>对嵌入式数据模型的支持减少了数据库系统上I/O活动。</p><p>索引支持更快的查询，并且可以包含来自嵌入式文档和数组的键。（文本索引解决搜索的需求、TTL索引解决历史数据自动过期的需求、地理位置索引可用于构建各种O2O应用）</p><p>mmapv1、 wiredtiger、 mongorocks（ rocks）、 In-memory等多引擎支持满足各种场景需求</p><p>Gridfs解决文件存储的需求</p><p>（2）高可用性</p><p>MongoDB的复制工具称为副本集（ replica set），它可提供自动故障转移和数据冗余</p><p>（3）高扩展性</p><p>MongoDB提供了水平可扩展性作为其核心功能的一部分。</p><p>分片将数据分布在一组集群的机器上。（海量数据存储，服务能力水平扩展）</p><p>从3.4开始，MoηgoDB支持基于片键创建数据区域。在一个平衡的集群中， MongoDB将一个区域所覆盖的读写只定向到该区域内的那些片。</p><p>（4）丰富的查询支持</p><p>MongoDB支持丰富的査询语言，支持读和写操作（CRUD），比如数据聚合、文本搜索和地理空间查询等</p><p>（5）其他特点</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3&gt;
Scrapy框架
&lt;/h3&gt;

&lt;p&gt;Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。 可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。&lt;/p&gt;
&lt;p&gt;所谓网络爬虫，就是一个在网上到处或定向抓取数据的程序，当然，这种说法不够专业，更专</summary>
      
    
    
    
    <category term="大数据导论" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AF%BC%E8%AE%BA/"/>
    
    
    <category term="课程设计" scheme="http://example.com/tags/%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>基于大数据方法的豆瓣电影短评分类、预测与搜索（三）:模型介绍</title>
    <link href="http://example.com/2022/11/17/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AF%BC%E8%AE%BA%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A12/"/>
    <id>http://example.com/2022/11/17/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AF%BC%E8%AE%BA%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A12/</id>
    <published>2022-11-16T16:00:00.000Z</published>
    <updated>2023-03-26T16:17:19.272Z</updated>
    
    <content type="html"><![CDATA[<h3>Scrapy框架</h3><p>Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。 可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。</p><p>所谓网络爬虫，就是一个在网上到处或定向抓取数据的程序，当然，这种说法不够专业，更专业的描述就是，抓取特定网站网页的HTML数据。抓取网页的一般方法是，定义一个入口页面，然后一般一个页面会有其他页面的URL，于是从当前页面获取到这些URL加入到爬虫的抓取队列中，然后进入到新页面后再递归的进行上述的操作，其实说来就跟深度遍历或广度遍历一样。</p><p>Scrapy 使用 Twisted这个异步网络库来处理网络通讯，架构清晰，并且包含了各种中间件接口，可以灵活的完成各种需求。</p><h3>Hadoop</h3><h4>背景</h4><p>Hadoop是一个由Apache基金会所开发的<a href="https://baike.baidu.com/item/分布式系统/4905336?fromModule=lemma_inlink">分布式系统</a>基础架构。用户可以在不了解分布式底层细节的情况下，开发分布式程序。充分利用集群的威力进行高速运算和存储。Hadoop实现了一个<a href="https://baike.baidu.com/item/分布式文件系统/1250388?fromModule=lemma_inlink">分布式文件系统</a>（ Distributed File System），其中一个组件是<a href="https://baike.baidu.com/item/HDFS/4836121?fromModule=lemma_inlink">HDFS</a>（Hadoop Distributed File System）。HDFS有高<a href="https://baike.baidu.com/item/容错性/9131391?fromModule=lemma_inlink">容错性</a>的特点，并且设计用来部署在低廉的（low-cost）硬件上；而且它提供高吞吐量（high throughput）来访问<a href="https://baike.baidu.com/item/应用程序/5985445?fromModule=lemma_inlink">应用程序</a>的数据，适合那些有着超大数据集（large data set）的应用程序。HDFS放宽了（relax）<a href="https://baike.baidu.com/item/POSIX/3792413?fromModule=lemma_inlink">POSIX</a>的要求，可以以流的形式访问（streaming access）文件系统中的数据。Hadoop的框架最核心的设计就是：<a href="https://baike.baidu.com/item/HDFS/4836121?fromModule=lemma_inlink">HDFS</a>和<a href="https://baike.baidu.com/item/MapReduce/133425?fromModule=lemma_inlink">MapReduce</a>。HDFS为海量的数据提供了存储，而MapReduce则为海量的数据提供了计算。</p><h4>优点</h4><p>Hadoop是一个能够让用户轻松架构和使用的分布式计算平台。用户可以轻松地在Hadoop上开发和运行处理海量数据的应用程序。它主要有以下几个优点：&lt;/br&gt;<br>1.高可靠性。Hadoop按位存储和处理数据的能力值得人们信赖&lt;/br&gt;。&lt;/br&gt;<br>2.高扩展性。Hadoop是在可用的计算机集簇间分配数据并完成计算任务的，这些集簇可以方便地扩展到数以千计的节点中。&lt;/br&gt;<br>3.高效性。Hadoop能够在节点之间动态地移动数据，并保证各个节点的动态平衡，因此处理速度非常快。&lt;/br&gt;<br>4.高容错性。Hadoop能够自动保存数据的多个副本，并且能够自动将失败的任务重新分配。&lt;/br&gt;<br>5.低成本。与一体机、商用数据仓库以及QlikView、Yonghong Z-Suite等数据集市相比，hadoop是开源的，项目的软件成本因此会大大降低。&lt;/br&gt;<br>Hadoop带有用Java语言编写的框架，因此运行在 Linux 生产平台上是非常理想的。Hadoop 上的应用程序也可以使用其他语言编写，比如C++。</p><h3>Spark </h3><p>   Spark使用Scala语言进行实现，它是一种面向对象、函数式编程语言，能够像操作本地集合对象一样轻松地操作分布式数据集，具有以下特点。<br>1.运行速度快：Spark拥有DAG执行引擎，支持在内存中对数据进行迭代计算。官方提供的数据表明，如果数据由磁盘读取，速度是Hadoop MapReduce的10倍以上，如果数据从内存中读取，速度可以高达100多倍。<br>2.易用性好：Spark不仅支持Scala编写应用程序，而且支持Java和Python等语言进行编写，特别是Scala是一种高效、可拓展的语言，能够用简洁的代码处理较为复杂的处理工作。&lt;/br&gt;<br>3.通用性强：Spark生态圈即BDAS（伯克利数据分析栈）包含了Spark Core、Spark SQL、Spark Streaming、MLLib和GraphX等组件，这些组件分别处理Spark Core提供内存计算框架、SparkStreaming的实时处理应用、Spark SQL的即席查询、MLlib或MLbase的机器学习和GraphX的图处理。<br>4.随处运行：Spark具有很强的适应性，能够读取HDFS、Cassandra、HBase、S3和Techyon为持久层读写原生数据，能够以Mesos、YARN和自身携带的Standalone作为资源管理器调度job，来完成Spark应用程序的计算。</p><h3>Mongodb</h3><h2>背景介绍</h2><p>MongoDB是一个基于分布式文件存储的数据库。</p><p>由C++语言编写，旨在为WEB应用提供可扩展的高性能数据存储解决方案。</p><p>MongoDB是一个介于关系数据库和非关系数据库之间的产品，是非关系数据库当中功能最丰富，最像关系数据库的。</p><p>它支持的数据结构非常松散，是类似json的bson格式，因此可以存储比较复杂的数据类型。</p><p>Mongo最大的特点是它支持的查询语言非常强大，其语法有点类似于面向对象的查询语言，几乎可以实现类似关系数据库单表查询的绝大部分功能，而且还支持对数据建立索引。</p><h2>业务场景</h2><p>传统的关系型数据库(如MySQL)，在数据操作的三高需求以及应对Web2.0的网站需求面前，显得力不从心，而 MongoDB可应对“三高“需求：</p><p>High performance：对数据库高并发读写的需求</p><p>Huge Storage：对海量数据的高效率存储和访问的需求</p><p>High Scalability &amp;&amp; High Availability：对数据库的高可扩展性和高可用性的需求</p><p>具体应用场景：</p><p>社交场景，使用 MongoDB存储存储用户信息，以及用户发表的朋友圈信息，通过地理位置索引实现附近的人、地点等功能。</p><p>游戏场景，使用 MongoDB存储游戏用户信息，用户的装备、积分等直接以内嵌文档的形式存储，方便查询、高效率存储和访问。</p><p>物流场景，使用 MongoDB存储订单信息，订单状态在运送过程中会不断更新，以 MongoDB内嵌数组的形式来存储，一次查询就能将订单所有的变更读取出来</p><p>物联网场景，使用 MongoDB存储所有接入的智能设备信息，以及设备汇报的日志信息，并对这些信息进行多维度的分析。</p><p>视频直播，使用 MongoDB存储用户信息、点赞互动信息等。</p><p>这些应用场景中，数据操作方面的共同特点是：</p><p>（1）数据量大</p><p>（2）写入操作频繁（读写都很频繁）</p><p>（3）价值较低的数据，对事务性要求不高</p><p>对于这样的数据，我们更适合使用 MongoDB来实现数据的存储。</p><h2>特点</h2><p>（1）高性能</p><p>MongoDB提供高性能的数据持久性。特别是，</p><p>对嵌入式数据模型的支持减少了数据库系统上I/O活动。</p><p>索引支持更快的查询，并且可以包含来自嵌入式文档和数组的键。（文本索引解决搜索的需求、TTL索引解决历史数据自动过期的需求、地理位置索引可用于构建各种O2O应用）</p><p>mmapv1、 wiredtiger、 mongorocks（ rocks）、 In-memory等多引擎支持满足各种场景需求</p><p>Gridfs解决文件存储的需求</p><p>（2）高可用性</p><p>MongoDB的复制工具称为副本集（ replica set），它可提供自动故障转移和数据冗余</p><p>（3）高扩展性</p><p>MongoDB提供了水平可扩展性作为其核心功能的一部分。</p><p>分片将数据分布在一组集群的机器上。（海量数据存储，服务能力水平扩展）</p><p>从3.4开始，MoηgoDB支持基于片键创建数据区域。在一个平衡的集群中， MongoDB将一个区域所覆盖的读写只定向到该区域内的那些片。</p><p>（4）丰富的查询支持</p><p>MongoDB支持丰富的査询语言，支持读和写操作（CRUD），比如数据聚合、文本搜索和地理空间查询等</p><p>（5）其他特点</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3&gt;
Scrapy框架
&lt;/h3&gt;

&lt;p&gt;Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。 可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。&lt;/p&gt;
&lt;p&gt;所谓网络爬虫，就是一个在网上到处或定向抓取数据的程序，当然，这种说法不够专业，更专</summary>
      
    
    
    
    <category term="大数据导论" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AF%BC%E8%AE%BA/"/>
    
    
    <category term="课程设计" scheme="http://example.com/tags/%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>基于大数据方法的豆瓣电影短评分类、预测与搜索（四）:了解NLP的卷积神经网络</title>
    <link href="http://example.com/2022/11/17/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AF%BC%E8%AE%BA%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A13/"/>
    <id>http://example.com/2022/11/17/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AF%BC%E8%AE%BA%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A13/</id>
    <published>2022-11-16T16:00:00.000Z</published>
    <updated>2023-03-27T06:46:23.948Z</updated>
    
    <content type="html"><![CDATA[<h3>了解NLP的卷积神经网络</h3><p>当我们听到卷积神经网络（CNN）时，我们通常会想到计算机视觉。CNN负责图像分类的重大突破，并且是当今大多数计算机视觉系统的核心，从Facebook的自动照片标记到自动驾驶汽车。</p><p>最近，我们也开始将CNN应用于自然语言处理中的问题，并得到了一些有趣的结果。在这篇文章中，我将尝试总结CNN是什么，以及它们如何在NLP中使用。对于计算机视觉用例来说，CNN背后的直觉更容易理解，所以我将从那里开始，然后慢慢转向NLP。</p><h4>什么是卷积？</h4><p>对我来说，理解<em>卷积</em>的最简单方法是将其视为应用于矩阵的滑动窗口函数。这很拗口，但看可视化就很清楚了：</p><p><img src="https://dennybritz.com/img/Convolution_schematic.gif" alt=""></p><p>带 3×3 滤波器的卷积，来源：<a href="http://deeplearning.stanford.edu/tutorial/supervised/FeatureExtractionUsingConvolution/">http://deeplearning.stanford.edu/tutorial/supervised/FeatureExtractionUsingConvolution/</a></p><p>想象一下，左边的矩阵表示一个黑白图像。每个条目对应一个像素，0 表示黑色，1 表示白色（灰度图像通常在 0 到 255 之间）。滑动窗口称为内核、过滤器<em>或</em>特征检测器。在这里，我们使用 3×3 过滤器，将其值逐个乘以原始矩阵，然后将它们相加。为了获得完整的卷积，我们通过在整个矩阵上滑动过滤器来为每个元素执行此操作。</p><p>您可能想知道您实际上可以用它做什么。以下是一些直观的例子。</p><h4 id="将每个像素与其相邻值求平均值会使图像模糊："><a href="#将每个像素与其相邻值求平均值会使图像模糊：" class="headerlink" title="将每个像素与其相邻值求平均值会使图像模糊："></a>将每个像素与其相邻值求平均值会使图像模糊：</h4><p><img src="https://docs.gimp.org/en/images/filters/examples/convolution-blur.png" alt=""></p><p><img src="https://docs.gimp.org/en/images/filters/examples/generic-taj-convmatrix-blur.jpg" alt=""></p><h4 id="取像素与其相邻像素之间的差异可检测边缘："><a href="#取像素与其相邻像素之间的差异可检测边缘：" class="headerlink" title="取像素与其相邻像素之间的差异可检测边缘："></a>取像素与其相邻像素之间的差异可检测边缘：</h4><p>（要直观地理解这一点，请考虑图像中平滑的部分会发生什么，其中像素颜色等于其相邻颜色的颜色：添加取消，结果值为 0 或黑色。如果强度有锋利的边缘，例如从白色到黑色的过渡，你会得到很大的差异和由此产生的白色值）</p><p><img src="https://docs.gimp.org/en/images/filters/examples/convolution-edge-detect1.png" alt=""></p><p><img src="https://docs.gimp.org/en/images/filters/examples/generic-taj-convmatrix-edge-detect.jpg" alt=""></p><h3 id="什么是卷积神经网络？"><a href="#什么是卷积神经网络？" class="headerlink" title="什么是卷积神经网络？#"></a>什么是卷积神经网络？<a href="https://dennybritz.com/posts/wildml/understanding-convolutional-neural-networks-for-nlp/#what-areconvolutional-neural-networks">#</a></h3><p>现在你知道什么是卷积了。但是CNN呢？CNN本质上是几层卷积，其中非线性<em>激活函数</em>（如<a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks">ReLU</a>)或<a href="https://reference.wolfram.com/language/ref/Tanh.html">tanh</a>）应用于结果。在传统的前馈神经网络中，我们将每个输入神经元连接到下一层的每个输出神经元。这也称为全连接层或仿射层。在CNN中，我们改为在输入层上使用卷积来计算输出。这会导致本地连接，其中输入的每个区域都连接到输出中的一个神经元。每个图层应用不同的过滤器，通常为数百或数千个，如上所示，并组合其结果。还有一些东西叫做池化（子采样）层，但我稍后会谈到这一点。在训练阶段，<strong>CNN</strong> 会根据您要执行的任务自动<strong>学习其过滤器的值</strong>。例如，图像分类 CNN 可以学习从第一层中的原始像素检测边缘，然后使用边缘检测第二层中的简单形状，然后使用这些形状来阻止更高级别的特征，例如较高层中的面部形状。最后一层是使用这些高级功能的分类器。</p><p><img src="https://dennybritz.com/wp-content/uploads/2015/11/Screen-Shot-2015-11-07-at-7.26.20-AM.png" alt=""></p><p>这种计算有两个方面值得关注：<strong>位置不变性和**</strong>组合性<em>*。假设您要对图像中是否存在大象进行分类。因为你在整个图像上滑动滤镜，所以你并不真正关心大象出现</em>在哪里<em>。在实践中，</em>池化<em>还可以为您提供平移、旋转和缩放的不变性，但稍后会详细介绍。第二个关键方面是（局部）组成性。每个过滤器</em>将*较低级别要素的局部修补程序组成为更高级别表示形式。这就是为什么CNN在计算机视觉中如此强大的原因。从像素构建边缘、从边缘构建形状以及从形状构建更复杂的对象，这很直观。</p><h4 id="那么，这些如何适用于NLP？"><a href="#那么，这些如何适用于NLP？" class="headerlink" title="那么，这些如何适用于NLP？"></a>那么，这些如何适用于NLP？</h4><p>大多数NLP任务的输入不是图像像素，而是表示为矩阵的句子或文档。矩阵的每一行对应于一个标记，通常是一个单词，但它可以是字符。也就是说，每一行都是表示一个单词的向量。通常，这些向量是<em>词嵌入</em>（低维表示），如<a href="https://code.google.com/p/word2vec/">word2vec</a>或<a href="http://nlp.stanford.edu/projects/glove/">GloVe</a>，但它们也可能是将单词索引为词汇表的单热向量。对于使用 10 维嵌入的 100 个单词的句子，我们将有一个 10×100 矩阵作为我们的输入。这就是我们的“形象”。</p><p>在视觉中，我们的过滤器在图像的局部斑块上滑动，但在NLP中，我们通常使用在矩阵（单词）的整行上滑动的过滤器。因此，过滤器的“宽度”通常与输入矩阵的宽度相同。高度或<em>区域大小</em>可能会有所不同，但一次超过 2-5 个单词的滑动窗口是典型的。综上所述，NLP 的卷积神经网络可能如下所示（花几分钟时间尝试理解这张图片以及如何计算维度。您现在可以忽略池化，稍后我们将解释）：</p><p><img src="https://dennybritz.com/wp-content/uploads/2015/11/Screen-Shot-2015-11-06-at-12.05.40-PM.png" alt=""></p><p>用于句子分类的卷积神经网络 （CNN） 架构图示。在这里，我们描述了三个过滤器区域大小：2、3 和 4，每个都有 2 个过滤器。每个过滤器对句子矩阵执行卷积并生成（可变长度）特征图。然后对每个图执行 1-max 池化，即记录每个特征图中的最大数量。因此，从所有六个映射生成一个单变量特征向量，并将这 6 个特征连接起来形成倒数第二层的特征向量。然后，最终的softmax层接收此特征向量作为输入，并使用它来对句子进行分类;这里我们假设二元分类，因此描述了两种可能的输出状态。资料来源：hang， Y.， &amp; Wallace， B. （2015）.用于句子分类的卷积神经网络的敏感性分析.</p><p>我们对计算机视觉的直觉呢？位置不变性和局部组合性对于图像来说很直观，但对于NLP来说就不那么重要了。你可能非常关心句子中出现单词的位置。彼此接近的像素可能在语义上相关（同一对象的一部分），但对于单词并不总是如此。在许多语言中，短语的某些部分可以用其他几个单词分隔。构图方面也不明显。显然，单词以某些方式组成，例如修饰名词的形容词，但这究竟是如何工作的，更高层次的表示实际上“意味着”并不像计算机视觉案例那样明显。</p><p>考虑到这一切，CNN似乎不适合NLP任务。<a href="https://dennybritz.com/posts/wildml/recurrent-neural-networks-tutorial-part-1/">递归神经网络</a>更直观。它们类似于我们处理语言的方式，或者至少是我们认为我们处理语言的方式：从左到右依次阅读。幸运的是，这并不意味着CNN不起作用。<a href="https://en.wikipedia.org/wiki/All_models_are_wrong">所有模型都是错误的，但有些模型是有用的</a>。事实证明，应用于NLP问题的CNN表现得非常好。简单的<a href="https://en.wikipedia.org/wiki/Bag-of-words_model">Bag of Words模型</a>显然过于简单，假设不正确，但多年来一直是标准方法，并产生了相当好的结果。</p><p>CNN的一个重要论点是它们速度很快。非常快。卷积是计算机图形学的核心部分，在 GPU 上的硬件级别实现。与<a href="https://en.wikipedia.org/wiki/N-gram">n-grams</a>相比，CNN在表示方面也很<em>有效</em>。对于大量词汇，计算超过 3 克的任何东西很快就会变得昂贵。甚至谷歌也没有提供超过5克的任何东西。卷积过滤器会自动学习良好的表示，而无需表示整个词汇表。使用大于 5 的过滤器是完全合理的。我喜欢认为第一层中的许多学习过滤器捕获的特征与 n 元语法非常相似（但不限于），但以更紧凑的方式表示它们。</p><h3 id="CNN-Hyperparameters"><a href="#CNN-Hyperparameters" class="headerlink" title="CNN Hyperparameters"></a>CNN Hyperparameters</h3><p>在解释如何将CNN应用于NLP任务之前，让我们看一下构建CNN时需要做出的一些选择。希望这将帮助您更好地了解该领域的文献。</p><h4 id="Narrow-vs-Wide-convolution"><a href="#Narrow-vs-Wide-convolution" class="headerlink" title="Narrow vs. Wide convolution"></a>Narrow vs. Wide convolution</h4><p>当我在上面解释卷积时，我忽略了我们如何应用过滤器的一些细节。在矩阵中心应用 3×3 滤波器工作正常，但边缘呢？如何将过滤器应用于顶部和左侧没有任何相邻元素的矩阵的第一个元素？您可以使用<em>零填充</em>。所有落在矩阵之外的元素都被视为零。通过执行此操作，您可以将过滤器应用于输入矩阵的每个元素，并获得更大或相同大小的输出。添加零填充也称为宽卷积<strong>，</strong>不使用零填充将是<em>窄卷积</em>。1D 中的示例如下所示：</p><p><img src="https://dennybritz.com/wp-content/uploads/2015/11/Screen-Shot-2015-11-05-at-9.47.41-AM.png" alt=""></p><p>窄卷积与宽卷积。滤波器尺寸 5，输入尺寸 7。来源：用于句子建模的卷积神经网络（2014）</p><p>您可以看到，当您有一个相对于输入大小较大的过滤器时，卷积有多宽是有用的，甚至是必要的。在上面，窄卷积产生大小的输出(7−5)+1=3(7−5)+1=3，以及大小的宽卷积输出(7+2∗4−5)+1=11(7+2∗4−5)+1=11. 更一般地说，输出大小的公式为</p><script type="math/tex; mode=display">n_out=(n_{in}+2*n_padding-n_{filter})+1</script><h4 id="Stride-Size"><a href="#Stride-Size" class="headerlink" title="Stride Size"></a>Stride Size</h4><p>卷积的另一个超参数是<em>步幅大小</em>，它通过您希望在每一步移动过滤器的程度来定义。在上述所有示例中，步幅均为 1，并且过滤器的连续应用重叠。步幅越大，滤波器的应用越少，输出尺寸越小。<a href="http://cs231n.github.io/convolutional-networks/">Stanford cs231 website</a>以下内容显示了应用于一维输入的步幅大小 1 和 2：</p><p><img src="https://dennybritz.com/wp-content/uploads/2015/11/Screen-Shot-2015-11-05-at-10.18.08-AM.png" alt=""></p><p>卷积步幅大小。左：步幅大小 1。右：步幅大小 2。来源： <a href="http://cs231n.github.io/convolutional-networks/">http://cs231n.github.io/convolutional-networks/</a></p><p>在文献中，我们通常看到步幅大小为 1，但更大的步幅大小可能允许您构建一个行为类似于<a href="https://en.wikipedia.org/wiki/Recursive_neural_network">递归神经网络</a>的模型，即看起来像一棵树。</p><h4 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h4><p>卷积神经网络的一个关键方面是<em>池化层，</em>通常在卷积层之后应用。池化层对其输入进行子采样。最常见的方法是将其池化以应用�一个�<em>马·</em>对每个筛选器的结果进行操作。您不一定需要在完整矩阵上池化，也可以在窗口上池化。例如，下面显示了 2×2 窗口的最大池化。在 NLP 中，我们通常对整个输出应用池化，每个滤波器只产生一个数字：</p><p><img src="https://dennybritz.com/wp-content/uploads/2015/11/Screen-Shot-2015-11-05-at-2.18.38-PM.png" alt=""></p><p>CNN 中的最大池化。来源： <a href="http://cs231n.github.io/convolutional-networks/#pool">http://cs231n.github.io/convolutional-networks/#pool</a></p><p>为什么要池化？有几个原因。池化的一个属性是它提供固定大小的输出矩阵，这通常是分类所必需的。例如，如果您有 1，000 个筛选器，并且对每个筛选器应用最大池化，则无论筛选器的大小或输入的大小如何，都将获得 1000 维输出。这允许您使用可变大小的句子和可变大小的过滤器，但始终获得相同的输出维度以馈送到分类器中。</p><p>池化也会降低输出维度，但（希望）保留最突出的信息。您可以将每个过滤器视为检测特定特征，例如检测句子是否包含否定词，例如“不惊人”。如果此短语出现在句子中的某处，则对该区域应用筛选器的结果将产生较大的值，但在其他区域中将产生较小的值。通过执行 max 运算，您可以保留有关特征是否出现在句子中的信息，但您将丢失有关其确切显示位置的信息。但是，这些关于地点的信息真的没有用吗？是的，它是，它有点类似于一袋n-gram模型正在做的事情。您正在丢失有关局部性的全局信息（句子中发生某些事情的位置），但您保留了过滤器捕获的本地信息，例如“不惊人”与“惊人不惊人”非常不同。</p><p>在想象识别中，池化还为平移（移位）和旋转提供了基本的不变性。在某个区域上进行池化时，即使将图像移动或旋转几个像素，输出也将大致保持不变，因为无论如何，最大操作都会选择相同的值。</p><h4 id="Channels"><a href="#Channels" class="headerlink" title="Channels"></a>Channels</h4><p>我们需要了解的最后一个概念是<em>渠道</em>。通道是输入数据的不同“视图”。例如，在图像识别中，您通常具有RGB（红色，绿色，蓝色）通道。您可以跨通道应用卷积，权重不同或相等。在NLP中，你也可以想象有各种各样的通道：你可以为不同的单词嵌入（例如<a href="https://code.google.com/p/word2vec/">word2vec</a>和<a href="http://nlp.stanford.edu/projects/glove/">GloVe</a>）提供一个单独的通道，或者你可以有一个通道来表示用不同的语言表示的同一个句子，或者用不同的方式表达。</p><h3 id="卷积神经网络应用于NLP"><a href="#卷积神经网络应用于NLP" class="headerlink" title="卷积神经网络应用于NLP"></a>卷积神经网络应用于NLP</h3><p>现在让我们看看CNN在自然语言处理中的一些应用。我会尝试总结一些研究结果。我总是会错过许多有趣的应用程序，但我希望至少涵盖一些更受欢迎的结果。</p><p>最适合CNN似乎是分类任务，例如情绪分析，垃圾邮件检测或主题分类。卷积和池化操作会丢失有关单词本地顺序的信息，因此 PoS 标记或实体提取中的序列标记更难适应纯 CNN 架构（尽管并非不可能，您可以向输入添加位置特征）。</p><p>[1] 在各种分类数据集上评估 CNN 架构，主要由情感分析和主题分类任务组成。CNN架构在数据集上实现了非常好的性能，并在少数数据集上实现了最先进的性能。令人惊讶的是，本文中使用的网络非常简单，这就是它强大的原因。输入层是由连接的 <a href="https://code.google.com/p/word2vec/">word2vec</a> 词嵌入组成的句子。接下来是具有多个过滤器的卷积层，然后是最大池化层，最后是softmax分类器。该论文还以静态和动态词嵌入的形式尝试了两种不同的通道，其中一个通道在训练期间进行调整，另一个则不调整。之前在 [2] 中提出了类似但稍微复杂的架构。[6] 在此网络架构中添加了一个执行“语义聚类”的附加层。</p><p><img src="https://dennybritz.com/wp-content/uploads/2015/11/Screen-Shot-2015-11-06-at-8.03.47-AM.png" alt=""></p><p>[4] 从头开始训练 CNN，无需像 word2vec 或 GloVe 这样的预先训练的词向量。它将卷积直接应用于独热向量。作者还为输入数据提出了一种节省空间的词袋状表示，减少了网络需要学习的参数数量。在[5]中，作者用额外的无监督“区域嵌入”扩展了模型，该嵌入是使用CNN预测文本区域上下文来学习的。这些论文中的方法似乎适用于长篇文本（如电影评论），但它们在短文本（如推文）上的表现尚不清楚。直观地说，对短文本使用预先训练的单词嵌入比对长文本使用它们会产生更大的收益是有道理的。</p><p>构建CNN架构意味着有许多超参数可供选择，其中一些我在上面介绍过：输入响应（word2vec，GloVe，one-hot），卷积过滤器的数量和大小，池化策略（最大值，平均值）和激活函数（ReLU，tanh）。[7] 对 CNN 架构中不同超参数的影响进行了实证评估，调查了它们对多次运行的性能和方差的影响。如果您希望实现自己的CNN进行文本分类，那么使用本文的结果作为起点将是一个好主意。一些突出的结果是，最大池化总是胜过平均池化，理想的过滤器大小很重要但取决于任务，并且正则化似乎在所考虑的NLP任务中没有太大的不同。这项研究的一个警告是，所有数据集在文档长度方面都非常相似，因此相同的准则可能不适用于看起来有很大差异的数据。</p><p>[8] 探索用于关系提取和关系分类任务的 CNN。除了词向量之外，作者还使用词与感兴趣实体的相对位置作为卷积层的输入。此模型假定给定实体的位置，并且每个示例输入都包含一个关系。[9]和[10]探索了类似的模型。</p><p>CNN在NLP中的另一个有趣的用例可以在[11]和[12]中找到，来自Microsoft Research。这些论文描述了如何学习可用于信息检索的句子的语义有意义的表示。论文中给出的示例包括根据用户当前正在阅读的内容向用户推荐可能感兴趣的文档。句子表示基于搜索引擎日志数据进行训练。</p><p>大多数CNN架构以一种或另一种方式学习单词和句子的嵌入（低维表示），作为其训练过程的一部分。并非所有论文都关注训练的这一方面或研究学习嵌入的意义。[13]提出了一个CNN架构来预测Facebook帖子的主题标签，同时为单词和句子生成有意义的嵌入。然后，这些学习的嵌入成功地应用于另一项任务 - 向用户推荐可能感兴趣的文档，并根据点击流数据进行训练。</p><h4 id="Character-Level-CNNs"><a href="#Character-Level-CNNs" class="headerlink" title="Character-Level CNNs"></a>Character-Level CNNs</h4><p>到目前为止，所有提出的模型都是基于文字的。但也有人研究将CNN直接应用于角色。[14] 学习字符级嵌入，将它们与预先训练的词嵌入连接起来，并使用 CNN 进行词性标记。[15][16] 探索了使用 CNN 直接从角色中学习，而无需任何预先训练的嵌入。值得注意的是，作者使用了一个相对深度的网络，共有9层，并将其应用于情感分析和文本分类任务。结果表明，直接从字符级输入中学习在大型数据集（数百万个示例）上效果非常好，但在较小的数据集（数十万个示例）上表现不佳。[17] 探索了字符级卷积在语言建模中的应用，在每个时间步使用字符级 CNN 的输出作为 LSTM 的输入。相同的模型应用于各种语言。</p><p>令人惊讶的是，基本上上述所有论文都是在过去1-2年内发表的。显然，CNN之前在NLP方面已经有过出色的工作，就像从<a href="http://arxiv.org/abs/1103.0398">Scratch开始的自然语言处理（几乎）</a>一样，但是新结果和最新系统发布的步伐显然正在加快</p><p>參考链接：</p><p><a href="https://dennybritz.com/posts/wildml/understanding-convolutional-neural-networks-for-nlp/">Understanding Convolutional Neural Networks for NLP · Denny’s Blog (dennybritz.com)</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3&gt;
了解NLP的卷积神经网络
&lt;/h3&gt;

&lt;p&gt;当我们听到卷积神经网络（CNN）时，我们通常会想到计算机视觉。CNN负责图像分类的重大突破，并且是当今大多数计算机视觉系统的核心，从Facebook的自动照片标记到自动驾驶汽车。&lt;/p&gt;
&lt;p&gt;最近，我们也开始将CNN应用于</summary>
      
    
    
    
    <category term="大数据导论" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AF%BC%E8%AE%BA/"/>
    
    
    <category term="课程设计" scheme="http://example.com/tags/%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>基于大数据方法的豆瓣电影短评分类、预测与搜索（五）:基于余弦相似的搜索算法</title>
    <link href="http://example.com/2022/11/17/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AF%BC%E8%AE%BA%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A15/"/>
    <id>http://example.com/2022/11/17/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AF%BC%E8%AE%BA%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A15/</id>
    <published>2022-11-16T16:00:00.000Z</published>
    <updated>2023-03-27T07:03:02.761Z</updated>
    
    <content type="html"><![CDATA[<h3>基于余弦相似的搜索算法</h3><p>给一个例子：</p><p><a href="https://postimg.cc/p9WSKJRj"><img src="https://i.postimg.cc/1zwZhvdv/VRUP-2-IEP-G-5-L-2-C-VMO.png" alt="VRUP-2-IEP-G-5-L-2-C-VMO.png"></a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3&gt;
基于余弦相似的搜索算法
&lt;/h3&gt;

&lt;p&gt;给一个例子：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://postimg.cc/p9WSKJRj&quot;&gt;&lt;img src=&quot;https://i.postimg.cc/1zwZhvdv/VRUP-2-IEP-G-5-L-2-C-</summary>
      
    
    
    
    <category term="大数据导论" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AF%BC%E8%AE%BA/"/>
    
    
    <category term="课程设计" scheme="http://example.com/tags/%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>基于大数据方法的豆瓣电影短评分类、预测与搜索（五）:Transformer模型</title>
    <link href="http://example.com/2022/11/17/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AF%BC%E8%AE%BA%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A14/"/>
    <id>http://example.com/2022/11/17/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AF%BC%E8%AE%BA%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A14/</id>
    <published>2022-11-16T16:00:00.000Z</published>
    <updated>2023-03-27T06:55:26.152Z</updated>
    
    <content type="html"><![CDATA[<p>Transformer是一个利用注意力机制来提高模型训练速度的模型。关于注意力机制可以参看<a href="https://zhuanlan.zhihu.com/p/52119092">这篇文章</a>，trasnformer可以说是完全基于自注意力机制的一个深度学习模型，因为它适用于并行化计算，和它本身模型的复杂程度导致它在精度和性能上都要高于之前流行的RNN循环神经网络。</p><p>那什么是transformer呢？</p><p>你可以简单理解为它是一个黑盒子，当我们在做文本翻译任务是，我输入进去一个中文，经过这个黑盒子之后，输出来翻译过后的英文。</p><p><img src="https://pic4.zhimg.com/80/v2-1a4f5b236563d6307acb58cc5a95b2b7_720w.webp" alt=""></p><p>那么在这个黑盒子里面都有什么呢？</p><p>里面主要有两部分组成：Encoder 和 Decoder</p><p><img src="https://pic2.zhimg.com/80/v2-8bf3b3ac8836ef1a9f16e1669fb29511_720w.webp" alt=""></p><p>当我输入一个文本的时候，该文本数据会先经过一个叫Encoders的模块，对该文本进行编码，然后将编码后的数据再传入一个叫Decoders的模块进行解码，解码后就得到了翻译后的文本，对应的我们称Encoders为编码器，Decoders为解码器。</p><p>那么编码器和解码器里边又都是些什么呢？</p><p>细心的同学可能已经发现了，上图中的Decoders后边加了个s，那就代表有多个编码器了呗，没错，这个编码模块里边，有很多小的编码器，一般情况下，Encoders里边有6个小编码器，同样的，Decoders里边有6个小解码器。</p><p><img src="https://pic4.zhimg.com/80/v2-739d9498e0a36296240741be909d35f7_720w.webp" alt=""></p><p>我们看到，在编码部分，每一个的小编码器的输入是前一个小编码器的输出，而每一个小解码器的输入不光是它的前一个解码器的输出，还包括了整个编码部分的输出。</p><p>那么你可能又该问了，那每一个小编码器里边又是什么呢？</p><p>我们放大一个encoder，发现里边的结构是一个自注意力机制加上一个前馈神经网络。</p><p><img src="https://pic1.zhimg.com/80/v2-8c63aaf7e71b94fdb5d6df89abdaf118_720w.webp" alt=""></p><p>我们先来看下self-attention是什么样子的。</p><p>我们通过几个步骤来解释：</p><p>1、首先，self-attention的输入就是词向量，即整个模型的最初的输入是词向量的形式。那自注意力机制呢，顾名思义就是自己和自己计算一遍注意力，即对每一个输入的词向量，我们需要构建self-attention的输入。在这里，transformer首先将词向量乘上三个矩阵，得到三个新的向量，之所以乘上三个矩阵参数而不是直接用原本的词向量是因为这样增加更多的参数，提高模型效果。对于输入X1(机器)，乘上三个矩阵后分别得到Q1,K1,V1，同样的，对于输入X2(学习)，也乘上三个不同的矩阵得到Q2,K2,V2。</p><p><img src="https://pic3.zhimg.com/80/v2-15142b393f03a309c926754f00307d46_720w.webp" alt=""></p><p>2、那接下来就要计算注意力得分了，这个得分是通过计算Q与各个单词的K向量的点积得到的。我们以X1为例，分别将Q1和K1、K2进行点积运算，假设分别得到得分112和96。</p><p><img src="https://pic2.zhimg.com/80/v2-42ccd93ac7540619b02ef03faef21c15_720w.webp" alt=""></p><p>3、将得分分别除以一个特定数值8（K向量的维度的平方根，通常K向量的维度是64）这能让梯度更加稳定，则得到结果如下：</p><p><img src="https://pic3.zhimg.com/80/v2-8a98e66c20fb25e96e1f690309ae6166_720w.webp" alt=""></p><p>4、将上述结果进行softmax运算得到，softmax主要将分数标准化，使他们都是正数并且加起来等于1。</p><p><img src="https://pic3.zhimg.com/80/v2-1701b674a3e09ae91301d6cd9727f912_720w.webp" alt=""></p><p>5、将V向量乘上softmax的结果，这个思想主要是为了保持我们想要关注的单词的值不变，而掩盖掉那些不相关的单词（例如将他们乘上很小的数字）</p><p><img src="https://pic2.zhimg.com/80/v2-c18a30a6b8738af5cd1b5c0e2080e695_720w.webp" alt=""></p><p>6、将带权重的各个V向量加起来，至此，产生在这个位置上（第一个单词）的self-attention层的输出，其余位置的self-attention输出也是同样的计算方式。</p><p><img src="https://pic3.zhimg.com/80/v2-3577071e71ccfa49a4f60f4a5187f0ce_720w.webp" alt=""><br> 将上述的过程总结为一个公式就可以用下图表示：</p><p><img src="https://pic4.zhimg.com/80/v2-0190eb46d1c46efc04926821e69fd377_720w.webp" alt=""></p><p>self-attention层到这里就结束了吗？</p><p>还没有，论文为了进一步细化自注意力机制层，增加了“多头注意力机制”的概念，这从两个方面提高了自注意力层的性能。</p><p>第一个方面，他扩展了模型关注不同位置的能力，这对翻译一下句子特别有用，因为我们想知道“it”是指代的哪个单词。</p><p><img src="https://pic1.zhimg.com/80/v2-dc386abf38141384c43918689b0bbb64_720w.webp" alt=""></p><p>第二个方面，他给了自注意力层多个“表示子空间”。对于多头自注意力机制，我们不止有一组Q/K/V权重矩阵，而是有多组（论文中使用8组），所以每个编码器/解码器使用8个“头”（可以理解为8个互不干扰自的注意力机制运算），每一组的Q/K/V都不相同。然后，得到8个不同的权重矩阵Z，每个权重矩阵被用来将输入向量投射到不同的表示子空间。</p><p>经过多头注意力机制后，就会得到多个权重矩阵Z，我们将多个Z进行拼接就得到了self-attention层的输出：</p><p><img src="https://pic2.zhimg.com/80/v2-1be30f537678c89b2768ed31ff5bb491_720w.webp" alt=""></p><p>上述我们经过了self-attention层，我们得到了self-attention的输出，self-attention的输出即是前馈神经网络层的输入，然后前馈神经网络的输入只需要一个矩阵就可以了，不需要八个矩阵，所以我们需要把这8个矩阵压缩成一个，我们怎么做呢？只需要把这些矩阵拼接起来然后用一个额外的权重矩阵与之相乘即可。</p><p><img src="https://pic4.zhimg.com/80/v2-7394f6eb418b403588b0ca5a6751749f_720w.webp" alt=""></p><p>最终的Z就作为前馈神经网络的输入。</p><p>接下来就进入了小编码器里边的前馈神经网模块了，关于前馈神经网络，网上已经有很多资料，在这里就不做过多讲解了，只需要知道，前馈神经网络的输入是self-attention的输出，即上图的Z,是一个矩阵，矩阵的维度是（序列长度×D词向量），之后前馈神经网络的输出也是同样的维度。</p><p>以上就是一个小编码器的内部构造了，一个大的编码部分就是将这个过程重复了6次，最终得到整个编码部分的输出。</p><p>然后再transformer中使用了6个encoder，为了解决梯度消失的问题，在Encoders和Decoder中都是用了残差神经网络的结构，即每一个前馈神经网络的输入不光包含上述self-attention的输出Z，还包含最原始的输入。</p><p>上述说到的encoder是对输入（机器学习）进行编码，使用的是自注意力机制+前馈神经网络的结构，同样的，在decoder中使用的也是同样的结构。也是首先对输出（machine learning）计算自注意力得分，不同的地方在于，进行过自注意力机制后，将self-attention的输出再与Decoders模块的输出计算一遍注意力机制得分，之后，再进入前馈神经网络模块。</p><p><img src="https://pic4.zhimg.com/v2-5e32534b9a651289cb3eb2b409d5996b_r.jpg" alt=""></p><p>以上，就讲完了Transformer编码和解码两大模块，那么我们回归最初的问题，将“机器学习”翻译成“machine learing”，解码器输出本来是一个浮点型的向量，怎么转化成“machine learing”这两个词呢？</p><p>是个工作是最后的线性层接上一个softmax，其中线性层是一个简单的全连接神经网络，它将解码器产生的向量投影到一个更高维度的向量（logits）上，假设我们模型的词汇表是10000个词，那么logits就有10000个维度，每个维度对应一个惟一的词的得分。之后的softmax层将这些分数转换为概率。选择概率最大的维度，并对应地生成与之关联的单词作为此时间步的输出就是最终的输出啦！！</p><p>假设词汇表维度是6，那么输出最大概率词汇的过程如下：</p><p><img src="https://pic4.zhimg.com/80/v2-6d0a0d38ab824914942121d1ae78cd0b_720w.webp" alt=""></p><p>以上就是Transformer的框架了，但是还有最后一个问题，我们都是到RNN中的每个输入是时序的，是又先后顺序的，但是Transformer整个框架下来并没有考虑顺序信息，这就需要提到另一个概念了：“位置编码”。</p><p>Transformer中确实没有考虑顺序信息，那怎么办呢，我们可以在输入中做手脚，把输入变得有位置信息不就行了，那怎么把词向量输入变成携带位置信息的输入呢？</p><p>我们可以给每个词向量加上一个有顺序特征的向量，发现sin和cos函数能够很好的表达这种特征，所以通常位置向量用以下公式来表示：</p><p><img src="https://pic1.zhimg.com/80/v2-a671b951ef42d09c349db12c35175998_720w.webp" alt=""></p><p><img src="https://pic1.zhimg.com/80/v2-c17ebc4594bd0c0d01fab289abde5ec4_720w.webp" alt=""></p><p>最后祭出这张经典的图，最初看这张图的时候可能难以理解，希望大家在深入理解Transformer后再看这张图能够有更深刻的认识。</p><p><img src="https://pic1.zhimg.com/80/v2-1d9129c9c0d5367591bd093f79155e40_720w.webp" alt=""></p><p><img src="https://pic4.zhimg.com/v2-8fbde14eac35db43cfe1734d4714a7db_r.jpg" alt=""></p><p>參考文獻：<a href="https://zhuanlan.zhihu.com/p/82312421">十分钟理解Transformer - 知乎 (zhihu.com)</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Transformer是一个利用注意力机制来提高模型训练速度的模型。关于注意力机制可以参看&lt;a href=&quot;https://zhuanlan.zhihu.com/p/52119092&quot;&gt;这篇文章&lt;/a&gt;，trasnformer可以说是完全基于自注意力机制的一个深度学习模型，</summary>
      
    
    
    
    <category term="大数据导论" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AF%BC%E8%AE%BA/"/>
    
    
    <category term="课程设计" scheme="http://example.com/tags/%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
</feed>
